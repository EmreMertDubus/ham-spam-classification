{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1239bc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the email is spam , spam = 1 ; else 0 . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10f89427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\"\"\"import nltk \n",
    "from nltk.corpus import stopwords\"\"\"\n",
    "import string\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from sklearn.feature_extraction.text import CountVectorizer , TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbc9d955",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  spam\n",
      "0  Subject: naturally irresistible your corporate...     1\n",
      "1  Subject: the stock trading gunslinger  fanny i...     1\n",
      "2  Subject: unbelievable new homes made easy  im ...     1\n",
      "3  Subject: 4 color printing special  request add...     1\n",
      "4  Subject: do not have money , get software cds ...     1\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"emails.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d893e05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5728, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print the shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bdba783",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_test , y_train , y_test = train_test_split(df[\"text\"],df[\"spam\"],test_size = 0.20,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8e78191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4582"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I converted it to np array, which was giving a dictionary key error. \n",
    "\n",
    "x_train_np = np.array(X_train)\n",
    "y_train_np = np.array(y_train)\n",
    "\n",
    "x_test_np = np.array(X_test)\n",
    "y_test_np = np.array(y_test)\n",
    "\n",
    "len(y_train_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9869f636",
   "metadata": {},
   "outputs": [],
   "source": [
    "#                                       SUMMARIZE ALL FORMULAS\n",
    "\n",
    "#                         To find conditional probablity formula for unique words . \n",
    "\n",
    "\n",
    "\n",
    "#                              (        counting of \"X\" words in spam/ham + 1           )\n",
    "#     P(X| ham or spam) =     --------------------------------------------------------------\n",
    "#                             (When row is spam/ham , count of all words + Unique word count)\n",
    "\n",
    "\n",
    "\n",
    "#       P(spam | Test(i)) = P(X1| spam) * P(X2|  spam) * ..... * P(X2|  spam) * P_Spam\n",
    "\n",
    "#       P(ham | Test(i)) = P(X1| ham) * P(X1| ham) * ..... * P(X1| ham) * P_Ham\n",
    "\n",
    "#       Whichever is larger, we make the classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bbd0fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find , List has only Ham rows . \n",
    "\n",
    "ham_only = list()\n",
    "ham_indices = list()\n",
    "for i in range(len(x_train_np)):\n",
    "    if y_train_np[i] == 0:\n",
    "        ham_only.append(x_train_np[i])\n",
    "        ham_indices.append(i)\n",
    "        \n",
    "# To find , List has only Spam rows .\n",
    "\n",
    "spam_only = list()\n",
    "spam_indices = list()\n",
    "for i in range(len(x_train_np)):\n",
    "    if y_train_np[i] == 1:\n",
    "        spam_only.append(x_train_np[i])\n",
    "        spam_indices.append(i)\n",
    "\n",
    "        \n",
    "        \n",
    "# ham_only : a list of only ham rows.\n",
    "# spam_only : a list of only spam rows.\n",
    "# ham/spam_indices : a list of indices of only ham/spam rows. To find , the total frequency of a word in a type (where?)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1aad1990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "895519"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When row is ham , count of all words \n",
    "\n",
    "def ham_all_words_count(onlyham):\n",
    "    \n",
    "    # I appended here all splitted words.\n",
    "    list_all_ham_words = list()\n",
    "    \n",
    "    for i in onlyham:\n",
    "        \n",
    "        list_all_ham_words += i.split(\" \")\n",
    "        \n",
    "        \n",
    "    # I appended here all word again without punctuation. Because i used np.array and np.array gum up my data with punc.\n",
    "    new_list_all_ham_words = list()\n",
    "    \n",
    "    for i in list_all_ham_words:\n",
    "        if i not in string.punctuation:\n",
    "            new_list_all_ham_words.append(i)\n",
    "    \n",
    "    # Conclusion i returned here , count of all words when mail is ham. \n",
    "    return len(new_list_all_ham_words)\n",
    "    \n",
    "    \n",
    "ham_all_words_count(ham_only)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f47bcdf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227250"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When row is spam , count of all words\n",
    "\n",
    "def spam_all_words_count(onlyspam):\n",
    "    \n",
    "    # I appended here all splitted words.\n",
    "    list_all_spam_words = list()\n",
    "    \n",
    "    for i in onlyspam:\n",
    "\n",
    "        list_all_spam_words += i.split(\" \")\n",
    "        \n",
    "\n",
    "    # I appended here all word again without punctuation. Because i used np.array and np.array gum up my data with punc.\n",
    "    new_list_all_spam_words = list()\n",
    "\n",
    "    for i in list_all_spam_words:\n",
    "        if i not in string.punctuation:\n",
    "            new_list_all_spam_words.append(i)\n",
    "    \n",
    "\n",
    "    # Conclusion i returned here , count of all words when mail is ham. \n",
    "    return len(new_list_all_spam_words)\n",
    "\n",
    "\n",
    "spam_all_words_count(spam_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab77745a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# buraya mat.plot ile iki türün kelime sayılarını grafikleştirebilirsin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b004c26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum_of_ham :  3475\n",
      "sum_of_spam :  1107\n",
      "P_Ham :  0.7584024443474465\n",
      "P_Spam :  0.24159755565255348\n"
     ]
    }
   ],
   "source": [
    "# We counted here \" How many HAM type of mail are there here ? \"\n",
    "\n",
    "sum_of_ham=0\n",
    "for i in range(len(y_train_np)):\n",
    "    if y_train_np[i] == 0 :\n",
    "        sum_of_ham+=1\n",
    "print(\"sum_of_ham : \" , sum_of_ham)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# We counted here \" How many SPAM type of mail are there here ? \"\n",
    "\n",
    "sum_of_spam=0\n",
    "for i in range(len(y_train_np)):\n",
    "    if y_train_np[i] == 1 :\n",
    "        sum_of_spam+=1\n",
    "print(\"sum_of_spam : \" , sum_of_spam)\n",
    "\n",
    "\n",
    "\n",
    "# For the formula : we compute here (sum of ham OR spam) / all mail counts\n",
    "p_ham = sum_of_ham / len(y_train_np)\n",
    "print(\"P_Ham : \" , p_ham)\n",
    "p_spam = sum_of_spam / len(y_train_np)\n",
    "print(\"P_Spam : \" , p_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "033a4100",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              ---     BAG OF WORDS (UNIQUE WORDS LIST)     ---         \n",
      "\n",
      "['00', '000', '01', '02', '03', '04', '05', '0500', '06', '0600', '07', '08', '09', '10', '100', '1092', '11', '12', '13', '14', '1400', '15', '150', '16', '17', '18', '19', '1998', '1999', '20', '200', '2000', '2001', '2002', '2004', '2005', '21', '212', '215', '22', '23', '24', '25', '250', '254', '26', '27', '28', '29', '30', '300', '31', '32', '33', '34', '345', '348', '35', '36', '37', '38', '3848', '39', '40', '41', '42', '43', '44', '4473', '45', '46', '47', '471', '48', '49', '50', '500', '51', '512', '52', '5290', '53', '54', '55', '56', '57', '58', '59', '60', '62', '646', '650', '66', '70', '710', '713', '75', '76798', '77002', '80', '800', '853', '90', '95', '98004', '99', 'ability', 'able', 'about', 'above', 'absolutely', 'academic', 'accept', 'accepted', 'access', 'according', 'account', 'accounting', 'accounts', 'accuracy', 'achieve', 'across', 'act', 'action', 'activities', 'actual', 'actually', 'add', 'added', 'addition', 'additional', 'address', 'addressed', 'addresses', 'administration', 'administrative', 'advance', 'advanced', 'advantage', 'advertisement', 'advertising', 'advice', 'advise', 'advisor', 'after', 'afternoon', 'again', 'against', 'agenda', 'agent', 'ago', 'agree', 'agreed', 'agreement', 'ahead', 'ahmad', 'air', 'al', 'alex', 'all', 'allow', 'allows', 'almost', 'alone', 'along', 'already', 'also', 'alternative', 'although', 'always', 'am', 'america', 'american', 'amitava', 'among', 'amount', 'an', 'analysis', 'analyst', 'analysts', 'and', 'andmanyother', 'andrew', 'anita', 'anjam', 'announce', 'announced', 'announcement', 'annual', 'another', 'answer', 'any', 'anyone', 'anything', 'anyway', 'aol', 'apologize', 'appear', 'appears', 'application', 'applications', 'applied', 'apply', 'appreciate', 'appreciated', 'approach', 'appropriate', 'approval', 'approved', 'approximately', 'april', 'are', 'area', 'areas', 'around', 'arrange', 'arrangements', 'arrive', 'article', 'articles', 'as', 'asap', 'ask', 'asked', 'asking', 'asset', 'assets', 'assist', 'assistance', 'assistant', 'associate', 'associated', 'associates', 'assume', 'assuming', 'assumptions', 'at', 'attached', 'attaching', 'attachment', 'attend', 'attending', 'attention', 'august', 'austin', 'automatically', 'availability', 'available', 'average', 'avoid', 'aware', 'away', 'back', 'background', 'bad', 'bank', 'banking', 'barry', 'base', 'based', 'basic', 'basis', 'baylor', 'be', 'because', 'become', 'been', 'before', 'begin', 'beginning', 'behalf', 'behind', 'being', 'believe', 'below', 'ben', 'benefit', 'benefits', 'berkeley', 'best', 'better', 'between', 'big', 'bill', 'billion', 'bit', 'black', 'board', 'bob', 'bonus', 'book', 'books', 'boost', 'both', 'bottom', 'box', 'brad', 'break', 'brief', 'bring', 'broadband', 'brown', 'budget', 'build', 'building', 'bulk', 'business', 'businesses', 'busy', 'but', 'buy', 'by', 'ca', 'calculation', 'calendar', 'california', 'call', 'called', 'came', 'campus', 'can', 'canada', 'candidate', 'candidates', 'cannot', 'capacity', 'capital', 'car', 'card', 'care', 'career', 'carlo', 'carr', 'case', 'cash', 'cause', 'cc', 'cd', 'celeste', 'cell', 'center', 'central', 'ceo', 'certain', 'certainly', 'chair', 'chairman', 'chance', 'change', 'changed', 'changes', 'charge', 'charges', 'charset', 'cheap', 'check', 'chief', 'choice', 'chonawee', 'choose', 'chris', 'christie', 'city', 'cl', 'class', 'clayton', 'clear', 'click', 'client', 'clients', 'close', 'closely', 'co', 'code', 'collaboration', 'colleague', 'colleagues', 'college', 'collins', 'com', 'come', 'comes', 'coming', 'comments', 'commerce', 'commercial', 'commission', 'commitment', 'committed', 'committee', 'commodity', 'common', 'communication', 'communications', 'companies', 'company', 'compensation', 'competition', 'competitive', 'competitors', 'complete', 'completed', 'completely', 'computer', 'concerned', 'concerning', 'concerns', 'conditions', 'conduct', 'conference', 'confidential', 'confidentiality', 'confirm', 'confirmation', 'confirmed', 'congratulations', 'consider', 'consideration', 'considered', 'considering', 'consistent', 'construction', 'consulting', 'contact', 'contacted', 'contacting', 'contacts', 'contain', 'contained', 'contains', 'content', 'contents', 'continue', 'continued', 'continuing', 'contract', 'contracts', 'contribution', 'control', 'convenience', 'convenient', 'conversation', 'coordinate', 'coordinator', 'copies', 'copy', 'copyright', 'corp', 'corporate', 'corporation', 'correct', 'cost', 'costs', 'could', 'countries', 'country', 'couple', 'course', 'cover', 'create', 'created', 'creating', 'creative', 'credit', 'crenshaw', 'critical', 'cross', 'crude', 'current', 'currently', 'curve', 'curves', 'custom', 'customer', 'customers', 'cut', 'daily', 'dale', 'data', 'database', 'date', 'dates', 'dave', 'david', 'day', 'days', 'de', 'deadline', 'deal', 'deals', 'dear', 'debt', 'dec', 'december', 'decide', 'decided', 'decision', 'decisions', 'default', 'definitely', 'delay', 'delete', 'deliver', 'delivered', 'delivery', 'demand', 'department', 'dept', 'derivative', 'derivatives', 'description', 'design', 'designed', 'desk', 'desktop', 'detail', 'detailed', 'details', 'determine', 'develop', 'developed', 'developing', 'development', 'developments', 'did', 'didn', 'difference', 'different', 'difficult', 'dinner', 'direct', 'direction', 'directly', 'director', 'directory', 'discount', 'discuss', 'discussed', 'discussing', 'discussion', 'discussions', 'distribution', 'do', 'doc', 'document', 'documents', 'does', 'doesn', 'doing', 'dollars', 'don', 'done', 'donna', 'down', 'download', 'dr', 'draft', 'dramatically', 'draw', 'drive', 'due', 'during', 'dynamic', 'each', 'earlier', 'early', 'easier', 'easily', 'eastern', 'easy', 'eb', 'ebl', 'ebs', 'economic', 'economics', 'economy', 'ect', 'ed', 'edition', 'edu', 'education', 'ees', 'effect', 'effective', 'efficient', 'effort', 'efforts', 'either', 'electric', 'electricity', 'electronic', 'else', 'email', 'emails', 'emerging', 'employee', 'employees', 'employment', 'ena', 'enclosed', 'encourage', 'end', 'energy', 'engineering', 'engines', 'enjoy', 'enjoyed', 'enough', 'enron', 'enronxgate', 'ensure', 'enter', 'entire', 'environment', 'equipment', 'equity', 'eric', 'error', 'especially', 'estimates', 'et', 'etc', 'europe', 'european', 'evaluation', 'even', 'evening', 'event', 'events', 'ever', 'every', 'everyone', 'everything', 'exactly', 'example', 'examples', 'excel', 'excellent', 'except', 'exchange', 'excited', 'exciting', 'executive', 'existing', 'expect', 'expected', 'expenses', 'experience', 'expertise', 'explain', 'exposure', 'express', 'expressed', 'ext', 'extended', 'extensive', 'extent', 'extra', 'extremely', 'facilitate', 'facilities', 'fact', 'factor', 'factors', 'faculty', 'failed', 'failure', 'fall', 'family', 'far', 'fast', 'fax', 'features', 'feb', 'february', 'federal', 'fee', 'feedback', 'feel', 'fees', 'few', 'field', 'file', 'files', 'fill', 'final', 'finally', 'finance', 'financial', 'find', 'fine', 'firm', 'first', 'fit', 'five', 'fixed', 'floor', 'flow', 'focus', 'focused', 'folks', 'follow', 'following', 'follows', 'for', 'forecast', 'forecasting', 'foreign', 'form', 'formal', 'format', 'formats', 'forms', 'forum', 'forward', 'forwarded', 'forwarding', 'found', 'four', 'frank', 'free', 'fresh', 'fri', 'friday', 'friend', 'friends', 'from', 'front', 'fuel', 'full', 'fully', 'function', 'functions', 'fund', 'funds', 'further', 'future', 'fw', 'fwd', 'fyi', 'gary', 'gas', 'gave', 'general', 'generate', 'generation', 'george', 'get', 'gets', 'getting', 'gibner', 'give', 'given', 'gives', 'giving', 'glad', 'global', 'go', 'goals', 'goes', 'going', 'gone', 'good', 'got', 'government', 'graduate', 'grant', 'graphics', 'great', 'greater', 'greatly', 'greetings', 'greg', 'group', 'groups', 'growing', 'growth', 'guarantee', 'guaranteed', 'guide', 'guy', 'guys', 'had', 'half', 'hall', 'hand', 'happen', 'happy', 'hard', 'has', 'have', 'haven', 'having', 'he', 'head', 'hear', 'heard', 'hearing', 'hedge', 'hedging', 'held', 'hello', 'help', 'helpful', 'helping', 'her', 'here', 'hesitate', 'hi', 'high', 'higher', 'highly', 'him', 'hire', 'hiring', 'his', 'historical', 'history', 'hold', 'holiday', 'home', 'hope', 'hopefully', 'host', 'hot', 'hotel', 'hou', 'hour', 'hours', 'house', 'houston', 'how', 'howard', 'however', 'hr', 'hsb', 'htm', 'html', 'http', 'huang', 'huge', 'human', 'id', 'idea', 'ideas', 'identified', 'identify', 'identity', 'if', 'ii', 'image', 'immediate', 'immediately', 'impact', 'implement', 'implementation', 'importance', 'important', 'impressed', 'impression', 'improve', 'improvement', 'in', 'inc', 'include', 'included', 'includes', 'including', 'income', 'increase', 'increased', 'independent', 'index', 'india', 'indicated', 'individual', 'individuals', 'industrial', 'industries', 'industry', 'info', 'inform', 'informal', 'information', 'informed', 'initial', 'input', 'instead', 'institute', 'institutions', 'instructions', 'insurance', 'integration', 'intended', 'interest', 'interested', 'interesting', 'interests', 'internal', 'international', 'internet', 'internship', 'interview', 'interviews', 'into', 'introduce', 'investment', 'investments', 'investor', 'investors', 'invitation', 'invite', 'invited', 'involve', 'involved', 'iris', 'is', 'iso', 'issler', 'issue', 'issued', 'issues', 'it', 'items', 'its', 'itself', 'james', 'jan', 'january', 'jason', 'jeff', 'jeffrey', 'jim', 'job', 'joe', 'john', 'join', 'joining', 'joint', 'jones', 'joseph', 'jul', 'julie', 'july', 'june', 'just', 'kaminski', 'keep', 'keeping', 'ken', 'kenneth', 'kevin', 'key', 'kim', 'kind', 'kindall', 'kindly', 'know', 'knowledge', 'known', 'kohli', 'krishna', 'krishnarao', 'kristin', 'la', 'lance', 'large', 'largest', 'last', 'late', 'later', 'latest', 'law', 'lay', 'lead', 'leadership', 'leading', 'learn', 'learned', 'least', 'leave', 'leaving', 'lee', 'left', 'legal', 'leppard', 'less', 'let', 'letter', 'level', 'license', 'life', 'light', 'like', 'likely', 'limit', 'limited', 'lin', 'line', 'link', 'links', 'list', 'listed', 'little', 'live', 'living', 'll', 'lng', 'load', 'loan', 'local', 'located', 'location', 'locations', 'log', 'logo', 'lon', 'london', 'long', 'longer', 'look', 'looking', 'looks', 'lose', 'loss', 'lost', 'lot', 'love', 'low', 'lower', 'lst', 'lu', 'lunch', 'mack', 'macromedia', 'made', 'magee', 'mail', 'mailer', 'mailing', 'mailings', 'mailto', 'main', 'major', 'make', 'makes', 'making', 'man', 'manage', 'management', 'manager', 'managers', 'managing', 'many', 'march', 'mark', 'market', 'marketing', 'markets', 'martin', 'martinj', 'mary', 'masson', 'material', 'materials', 'mathematics', 'matter', 'maureen', 'may', 'maybe', 'mba', 'me', 'mean', 'means', 'measure', 'media', 'meet', 'meeting', 'meetings', 'member', 'members', 'mention', 'mentioned', 'message', 'messages', 'met', 'method', 'methodology', 'methods', 'michael', 'mid', 'might', 'mike', 'million', 'mime', 'mind', 'mine', 'minute', 'minutes', 'model', 'modeling', 'modelling', 'models', 'molly', 'moment', 'monday', 'money', 'monte', 'month', 'monthly', 'months', 'moore', 'more', 'morning', 'most', 'move', 'moved', 'moving', 'mr', 'ms', 'much', 'multi', 'multiple', 'murphy', 'must', 'mx', 'my', 'myself', 'na', 'name', 'names', 'national', 'natural', 'nd', 'near', 'necessary', 'need', 'needed', 'needs', 'net', 'network', 'never', 'new', 'news', 'newsletter', 'next', 'nice', 'night', 'no', 'non', 'nor', 'norma', 'normal', 'north', 'not', 'note', 'notes', 'nothing', 'notice', 'notification', 'notify', 'nov', 'november', 'now', 'number', 'numbers', 'ny', 'objectives', 'obtain', 'oct', 'october', 'oem', 'of', 'off', 'offer', 'offered', 'offering', 'offers', 'office', 'officer', 'official', 'oil', 'ok', 'old', 'on', 'once', 'one', 'oniine', 'online', 'only', 'open', 'operating', 'operation', 'operational', 'operations', 'opinion', 'opinions', 'opportunities', 'opportunity', 'optimization', 'option', 'options', 'or', 'order', 'ordered', 'orders', 'org', 'organization', 'original', 'other', 'others', 'otherwise', 'our', 'out', 'outline', 'outside', 'outstanding', 'over', 'overall', 'overview', 'own', 'pa', 'package', 'packages', 'page', 'pages', 'paid', 'panel', 'paper', 'papers', 'part', 'participants', 'participate', 'participating', 'participation', 'particular', 'particularly', 'parties', 'partner', 'partners', 'party', 'pass', 'passed', 'password', 'past', 'path', 'patrick', 'paul', 'paulo', 'pay', 'payment', 'payments', 'pc', 'pdf', 'pending', 'people', 'per', 'perfect', 'performance', 'perhaps', 'period', 'permanent', 'person', 'personal', 'perspective', 'ph', 'phase', 'phd', 'phone', 'physical', 'pick', 'pinnamaneni', 'pipeline', 'place', 'placed', 'plan', 'planning', 'plans', 'plant', 'please', 'pleased', 'pleasure', 'plus', 'pm', 'po', 'point', 'points', 'policy', 'portfolio', 'position', 'positions', 'positive', 'possibility', 'possible', 'possibly', 'post', 'posted', 'potential', 'power', 'powerful', 'practical', 'prc', 'pre', 'prefer', 'prepare', 'prepared', 'present', 'presentation', 'presentations', 'presented', 'president', 'press', 'pretty', 'previous', 'previously', 'price', 'prices', 'pricing', 'primary', 'print', 'prior', 'priority', 'private', 'privileged', 'pro', 'probably', 'problem', 'problems', 'proceed', 'process', 'processes', 'processing', 'produce', 'product', 'production', 'products', 'prof', 'professional', 'professionals', 'professor', 'profile', 'profit', 'program', 'programs', 'progress', 'prohibited', 'project', 'projects', 'promotion', 'prompt', 'property', 'proposal', 'proposed', 'proven', 'provide', 'provided', 'provides', 'providing', 'ps', 'public', 'publication', 'publications', 'published', 'purchase', 'purpose', 'purposes', 'pursue', 'put', 'putting', 'quality', 'quantitative', 'question', 'questions', 'quick', 'quickly', 'quite', 'rac', 'range', 'rate', 'rates', 'rather', 'ravi', 'raymond', 'rd', 're', 'reach', 'reached', 'read', 'reading', 'ready', 'real', 'really', 'reason', 'reasons', 'receipt', 'receive', 'received', 'receiving', 'recent', 'recently', 'recipient', 'recommend', 'recommendation', 'recommendations', 'record', 'recruiting', 'reduce', 'reference', 'reflect', 'regard', 'regarding', 'regards', 'region', 'register', 'registered', 'registration', 'regular', 'regulatory', 'related', 'relations', 'relationship', 'release', 'relevant', 'remain', 'remember', 'reminder', 'remove', 'removed', 'reply', 'report', 'reporting', 'reports', 'represent', 'representative', 'request', 'requested', 'requests', 'require', 'required', 'requirements', 'requires', 'research', 'reservations', 'reserve', 'reserved', 'resource', 'resources', 'respect', 'respond', 'responding', 'response', 'responsibilities', 'responsibility', 'responsible', 'rest', 'result', 'results', 'resume', 'retail', 'return', 'returned', 'returns', 'revenue', 'revenues', 'review', 'rice', 'richard', 'rick', 'right', 'rights', 'risk', 'risks', 'robert', 'roberts', 'role', 'room', 'round', 'run', 'running', 'safe', 'said', 'sale', 'sales', 'same', 'san', 'sandeep', 'satisfaction', 'saturday', 'save', 'say', 'says', 'schedule', 'scheduled', 'schedules', 'scheduling', 'school', 'science', 'scope', 'scott', 'search', 'second', 'section', 'sector', 'secure', 'securities', 'security', 'see', 'seeing', 'seek', 'seem', 'seems', 'seen', 'select', 'selected', 'self', 'sell', 'selling', 'seminar', 'send', 'sender', 'sending', 'senior', 'sense', 'sent', 'separate', 'september', 'series', 'serious', 'serve', 'server', 'service', 'services', 'session', 'set', 'setting', 'several', 'sevil', 'sex', 'shall', 'shanbhogue', 'shankman', 'share', 'she', 'shipping', 'shirley', 'short', 'shortly', 'should', 'show', 'side', 'sign', 'signed', 'significant', 'significantly', 'similar', 'simple', 'simply', 'simulation', 'since', 'sincerely', 'single', 'site', 'sites', 'situation', 'six', 'size', 'skilling', 'skills', 'small', 'smith', 'smtp', 'so', 'soft', 'software', 'sold', 'solicitation', 'solution', 'solutions', 'some', 'someone', 'something', 'sometime', 'sometimes', 'soon', 'sorry', 'sounds', 'source', 'sources', 'south', 'space', 'speak', 'speaker', 'speakers', 'speaking', 'special', 'specific', 'specifically', 'speed', 'spend', 'spent', 'spoke', 'sponsored', 'spot', 'spread', 'spreadsheet', 'spring', 'st', 'staff', 'stage', 'stand', 'standard', 'stanford', 'start', 'started', 'starting', 'state', 'stated', 'statements', 'states', 'stationery', 'statistical', 'status', 'stay', 'step', 'stephen', 'steps', 'steve', 'steven', 'still', 'stinson', 'stock', 'stocks', 'stop', 'storage', 'strategic', 'strategies', 'strategy', 'stream', 'street', 'strictly', 'strong', 'structure', 'structuring', 'student', 'students', 'studies', 'studio', 'study', 'stuff', 'subject', 'submit', 'submitted', 'subscription', 'success', 'successful', 'such', 'suggest', 'suggested', 'suggestions', 'suite', 'summary', 'summer', 'sun', 'sunday', 'supervisor', 'supply', 'support', 'supporting', 'surbey', 'sure', 'system', 'systems', 'table', 'take', 'taken', 'takes', 'taking', 'talk', 'talked', 'talking', 'tamarchenko', 'tanya', 'task', 'tax', 'team', 'teams', 'technical', 'techniques', 'technologies', 'technology', 'ted', 'tel', 'telephone', 'tell', 'term', 'terms', 'test', 'testing', 'texas', 'text', 'th', 'than', 'thank', 'thanks', 'that', 'the', 'their', 'them', 'then', 'there', 'therefore', 'these', 'they', 'thing', 'things', 'think', 'thinking', 'third', 'this', 'thomas', 'those', 'though', 'thought', 'thoughts', 'thousand', 'thousands', 'three', 'through', 'throughout', 'thuraisingham', 'thursday', 'thus', 'tiger', 'till', 'tim', 'time', 'times', 'title', 'to', 'today', 'together', 'told', 'tom', 'tomorrow', 'tony', 'too', 'took', 'tool', 'tools', 'top', 'topic', 'topics', 'total', 'touch', 'towards', 'town', 'track', 'trade', 'trader', 'traders', 'trading', 'training', 'transaction', 'transactions', 'transfer', 'transmission', 'transportation', 'travel', 'tried', 'trip', 'true', 'trust', 'try', 'trying', 'tue', 'tuesday', 'turn', 'two', 'tx', 'type', 'types', 'uk', 'unable', 'under', 'understand', 'understanding', 'understood', 'unfortunately', 'unique', 'unit', 'united', 'units', 'university', 'unless', 'unlimited', 'unsubscribe', 'until', 'up', 'upcoming', 'update', 'updated', 'upenn', 'upon', 'urgent', 'url', 'us', 'usa', 'use', 'used', 'useful', 'user', 'users', 'uses', 'using', 'ut', 'utexas', 'utilities', 'utility', 'vacation', 'valuable', 'valuation', 'value', 'var', 'various', 'vasant', 've', 'version', 'versions', 'very', 'via', 'viagra', 'vice', 'video', 'view', 'vince', 'vincent', 'visa', 'visit', 'visiting', 'vkamins', 'vkaminski', 'voice', 'volatility', 'volume', 'vp', 'waco', 'wait', 'waiting', 'want', 'wanted', 'wants', 'was', 'washington', 'watch', 'way', 'ways', 'we', 'weather', 'web', 'website', 'wed', 'wednesday', 'week', 'weekend', 'weekly', 'weeks', 'welcome', 'well', 'went', 'were', 'west', 'wharton', 'what', 'whatever', 'when', 'where', 'whether', 'which', 'while', 'who', 'whole', 'wholesale', 'whom', 'why', 'wide', 'will', 'william', 'williams', 'willing', 'windows', 'wish', 'wishes', 'with', 'within', 'without', 'won', 'wonderful', 'wondering', 'word', 'words', 'work', 'worked', 'working', 'works', 'workshop', 'world', 'worldwide', 'worth', 'would', 'write', 'writing', 'written', 'wrote', 'www', 'yahoo', 'year', 'years', 'yes', 'yesterday', 'yet', 'york', 'you', 'your', 'yours', 'yourself', 'zimin']\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.7369052  4.30160722 5.49007584 ... 5.26181719 5.26181719 3.86537046]\n",
      "[3.55596457 2.96688675 4.57632466 ... 1.35873999 4.54457596 3.8359246 ]\n",
      "How many unique words are there?  :  1926\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------- PART 2 -----------------------------------------------------\n",
    "\n",
    "# i used sklearn.CountVectorizer library\n",
    "# it is returned some words to create BoW. \n",
    "\n",
    "vectorizer = CountVectorizer(min_df=0.01)\n",
    "   \n",
    "X = vectorizer.fit_transform(x_train_np)\n",
    "\n",
    "vectorizer2 = CountVectorizer(ngram_range=(2, 2),min_df=0.01)\n",
    "X2 = vectorizer2.fit_transform(x_train_np)\n",
    "unique_words2 = vectorizer2.get_feature_names()\n",
    "\n",
    "# unique words name's list        ( BAG OF WORDS )\n",
    "unique_words = vectorizer.get_feature_names()\n",
    "print(\"                              ---     BAG OF WORDS (UNIQUE WORDS LIST)     ---         \")\n",
    "print()\n",
    "print(unique_words)\n",
    "print()\n",
    "\n",
    "# unique words frequency list for each row\n",
    "each_row_word_frequency = X.toarray()\n",
    "each_row_word_frequency2 = X2.toarray()\n",
    "\n",
    "\n",
    "# --------------------------TF-IDF-----------------------------------\n",
    "\n",
    "# here for part3 implementing tf idf only ham words\n",
    "\n",
    "ham_tf = Pipeline([('count', CountVectorizer(min_df=0.01)),\n",
    "                ('tfid', TfidfTransformer())]).fit(ham_only)\n",
    "ham_tf['count'].transform(ham_only).toarray()\n",
    "\n",
    "ham_tf_olasilik = ham_tf['tfid'].idf_\n",
    "print(ham_tf_olasilik)\n",
    "\n",
    "ham_tf_unique = ham_tf[\"count\"].get_feature_names()\n",
    "\n",
    "\n",
    "\n",
    "#  to find the most useful and useless words when guessing\n",
    "\n",
    "ham_tf_yararli = sorted(ham_tf_olasilik,reverse=True)[9]\n",
    "\n",
    "ham_tf_yararsiz = sorted(ham_tf_olasilik)[9]\n",
    "\n",
    "#--------------------------------------------------------------------\n",
    "\n",
    "# here for part3 implementing tf idf only spam words\n",
    "\n",
    "spam_tf = Pipeline([('count', CountVectorizer(min_df=0.01)),\n",
    "                ('tfid', TfidfTransformer())]).fit(spam_only)\n",
    "spam_tf['count'].transform(spam_only).toarray()\n",
    "\n",
    "spam_tf_olasilik = spam_tf['tfid'].idf_\n",
    "print(spam_tf_olasilik)\n",
    "\n",
    "spam_tf_unique = spam_tf[\"count\"].get_feature_names()\n",
    "\n",
    "\n",
    "\n",
    "#  to find the most useful and useless words when guessing\n",
    "\n",
    "spam_tf_yararli = sorted(spam_tf_olasilik,reverse=True)[9]\n",
    "\n",
    "spam_tf_yararsiz = sorted(spam_tf_olasilik)[9]\n",
    "\n",
    "# --------------------------TF-IDF-----------------------------------\n",
    "\n",
    "\n",
    "\n",
    "print(\"How many unique words are there?  : \", len(unique_words))\n",
    "\n",
    "# i did this because we have to calculate words frequency seperately...\n",
    "hamlarin_label_arrayi = list()\n",
    "hamlarin_label_arrayi2 = list()\n",
    "\n",
    "for i in ham_indices:\n",
    "    hamlarin_label_arrayi.append(each_row_word_frequency[i])\n",
    "    hamlarin_label_arrayi2.append(each_row_word_frequency2[i])\n",
    "\n",
    "spamlarin_label_arrayi = list()\n",
    "spamlarin_label_arrayi2 = list()\n",
    "\n",
    "for j in spam_indices:\n",
    "    spamlarin_label_arrayi.append(each_row_word_frequency[j])\n",
    "    spamlarin_label_arrayi2.append(each_row_word_frequency2[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d831613c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   HAM FREQUENCY\n",
      "\n",
      "\n",
      "\n",
      "[1310, 372, 1392, 1023, 1018, 1205, 846, 69, 678, 82, 669, 942, 848, 1758, 135, 75, 1329, 1186, 373, 481, 107, 691, 33, 553, 505, 472, 563, 63, 146, 718, 57, 3860, 2527, 56, 8, 5, 388, 111, 143, 394, 455, 407, 442, 18, 155, 342, 459, 419, 455, 1187, 40, 337, 155, 162, 115, 59, 125, 155, 132, 133, 113, 81, 127, 239, 113, 105, 117, 305, 75, 235, 146, 143, 101, 96, 129, 236, 83, 114, 163, 142, 153, 101, 108, 141, 114, 111, 131, 141, 69, 26, 83, 154, 27, 42, 154, 848, 58, 78, 81, 54, 71, 353, 52, 46, 78, 132, 117, 433, 1575, 240, 21, 79, 62, 55, 458, 73, 136, 101, 56, 25, 27, 114, 79, 102, 102, 90, 86, 110, 89, 161, 296, 447, 53, 51, 109, 83, 111, 54, 46, 3, 29, 44, 103, 45, 479, 223, 469, 88, 180, 9, 123, 107, 86, 280, 112, 79, 34, 57, 202, 1602, 153, 60, 70, 35, 150, 298, 1275, 54, 116, 116, 3834, 231, 149, 111, 96, 111, 2371, 375, 229, 64, 16734, 0, 81, 139, 277, 56, 46, 75, 103, 294, 137, 1782, 124, 159, 60, 210, 68, 46, 56, 200, 126, 85, 45, 304, 86, 164, 146, 236, 73, 68, 536, 3940, 211, 99, 217, 138, 85, 56, 157, 73, 4036, 76, 314, 266, 73, 117, 134, 76, 111, 183, 328, 59, 157, 84, 44, 46, 4668, 730, 59, 64, 291, 87, 75, 179, 198, 39, 92, 588, 109, 43, 62, 87, 578, 116, 31, 156, 40, 36, 91, 427, 72, 184, 292, 6125, 307, 99, 1005, 453, 125, 82, 58, 35, 258, 230, 518, 143, 74, 63, 207, 727, 247, 371, 96, 151, 95, 100, 59, 277, 141, 57, 390, 100, 4, 469, 34, 175, 118, 68, 93, 197, 95, 153, 83, 68, 149, 20, 982, 88, 71, 1338, 145, 3631, 159, 65, 85, 335, 1009, 125, 69, 122, 2782, 67, 188, 144, 107, 237, 203, 65, 76, 76, 79, 73, 75, 340, 61, 39, 3115, 11, 101, 129, 268, 94, 76, 68, 61, 155, 174, 100, 239, 79, 314, 101, 101, 12, 11, 220, 130, 77, 112, 50, 203, 321, 70, 29, 213, 118, 83, 170, 107, 57, 122, 50, 307, 138, 27, 68, 118, 72, 81, 3563, 333, 58, 205, 343, 76, 125, 84, 65, 34, 216, 142, 71, 92, 873, 252, 742, 35, 77, 59, 24, 172, 158, 41, 172, 56, 42, 65, 48, 59, 949, 168, 40, 151, 140, 77, 87, 92, 73, 47, 48, 55, 73, 82, 853, 66, 73, 48, 54, 52, 53, 96, 44, 222, 47, 48, 262, 178, 61, 119, 100, 84, 94, 107, 113, 159, 359, 42, 1298, 236, 76, 79, 399, 148, 952, 38, 72, 130, 376, 164, 120, 76, 33, 13, 644, 866, 95, 64, 91, 339, 325, 294, 249, 13, 181, 160, 51, 150, 242, 675, 141, 621, 225, 86, 400, 806, 381, 133, 86, 244, 76, 582, 58, 88, 366, 79, 76, 310, 70, 131, 38, 110, 35, 67, 34, 99, 173, 433, 117, 71, 402, 95, 113, 52, 211, 87, 67, 68, 303, 104, 145, 104, 123, 941, 55, 307, 82, 79, 283, 84, 323, 156, 60, 153, 463, 61, 70, 424, 175, 57, 231, 127, 112, 1457, 528, 140, 78, 312, 59, 181, 31, 372, 196, 96, 181, 66, 328, 164, 20, 8, 94, 268, 362, 28, 412, 159, 180, 37, 44, 88, 47, 221, 106, 239, 110, 124, 45, 9065, 99, 39, 1324, 82, 657, 68, 87, 55, 160, 117, 230, 143, 350, 125, 159, 933, 30, 62, 235, 202, 45, 268, 45, 50, 408, 1669, 278, 3, 38, 104, 78, 10781, 202, 89, 53, 66, 85, 87, 95, 103, 70, 80, 29, 147, 308, 183, 199, 92, 198, 145, 238, 106, 34, 144, 166, 78, 40, 135, 67, 66, 96, 46, 110, 58, 41, 180, 104, 92, 134, 57, 252, 51, 47, 86, 63, 57, 109, 29, 48, 45, 37, 57, 52, 65, 136, 79, 96, 133, 25, 41, 95, 81, 159, 57, 770, 63, 152, 234, 61, 64, 375, 342, 13, 448, 123, 305, 97, 39, 165, 64, 792, 578, 467, 116, 191, 559, 123, 43, 86, 178, 78, 146, 50, 53, 235, 676, 115, 10839, 86, 67, 54, 281, 55, 60, 6, 54, 100, 1090, 1180, 71, 121, 92, 107, 406, 18, 91, 671, 77, 60, 4200, 70, 133, 255, 50, 82, 88, 56, 39, 281, 293, 142, 81, 183, 92, 730, 84, 187, 23, 163, 117, 1186, 48, 201, 498, 562, 310, 38, 111, 180, 308, 469, 52, 65, 378, 37, 687, 163, 217, 205, 342, 14, 447, 39, 80, 89, 121, 1823, 150, 21, 70, 52, 19, 53, 83, 124, 675, 68, 96, 66, 67, 278, 114, 1687, 5025, 79, 198, 1666, 143, 141, 92, 192, 78, 106, 159, 305, 762, 67, 52, 349, 815, 89, 605, 263, 88, 86, 773, 70, 55, 921, 124, 46, 70, 68, 292, 536, 60, 47, 28, 225, 4372, 131, 165, 76, 1280, 710, 99, 405, 153, 87, 101, 287, 830, 81, 27, 49, 219, 146, 114, 45, 73, 2, 3482, 100, 57, 53, 157, 92, 52, 87, 30, 240, 46, 39, 55, 48, 11340, 193, 279, 131, 81, 263, 74, 124, 55, 56, 72, 212, 82, 104, 66, 192, 58, 335, 216, 73, 70, 1242, 70, 74, 110, 57, 92, 60, 50, 127, 48, 104, 399, 526, 138, 47, 103, 164, 299, 150, 733, 160, 512, 47, 169, 74, 25, 16, 215, 172, 67, 32, 139, 325, 7773, 100, 86, 312, 34, 361, 4128, 90, 630, 63, 150, 99, 260, 113, 363, 99, 221, 287, 148, 812, 203, 73, 46, 209, 69, 6, 200, 312, 227, 668, 3820, 193, 42, 145, 72, 503, 189, 157, 171, 102, 51, 1846, 94, 30, 89, 106, 130, 128, 76, 96, 122, 51, 688, 102, 180, 136, 55, 96, 111, 75, 83, 79, 45, 116, 150, 64, 101, 162, 117, 149, 119, 1451, 147, 237, 167, 71, 58, 1447, 141, 39, 101, 89, 184, 106, 61, 534, 148, 100, 54, 26, 508, 208, 118, 37, 70, 84, 187, 63, 61, 18, 644, 672, 350, 120, 792, 336, 129, 16, 68, 36, 201, 37, 41, 47, 85, 243, 265, 176, 1, 317, 100, 997, 24, 63, 10, 183, 127, 117, 755, 115, 180, 24, 80, 1111, 285, 58, 292, 449, 347, 414, 990, 116, 583, 400, 75, 49, 161, 81, 84, 86, 100, 188, 1596, 83, 144, 3139, 132, 73, 68, 37, 434, 1478, 155, 106, 264, 63, 189, 1146, 77, 107, 42, 106, 69, 261, 124, 401, 372, 137, 28, 129, 61, 43, 121, 1021, 217, 108, 371, 255, 41, 510, 80, 77, 250, 116, 239, 232, 1111, 424, 398, 234, 55, 115, 397, 142, 546, 47, 71, 91, 185, 25, 2449, 103, 491, 441, 123, 91, 199, 135, 65, 123, 1189, 122, 212, 203, 244, 64, 1447, 172, 100, 786, 87, 102, 754, 172, 47, 98, 49, 265, 2598, 300, 142, 29, 208, 32, 75, 111, 240, 600, 601, 153, 102, 39, 71, 172, 208, 1, 14696, 283, 336, 60, 42, 83, 644, 68, 128, 223, 155, 68, 9027, 190, 1166, 0, 137, 646, 222, 96, 45, 92, 260, 44, 39, 212, 385, 96, 440, 675, 2927, 432, 42, 34, 114, 143, 450, 943, 116, 92, 2356, 872, 58, 108, 37, 545, 83, 94, 131, 63, 95, 9, 165, 55, 54, 118, 354, 120, 345, 132, 138, 49, 203, 103, 60, 58, 35, 64, 71, 85, 45, 163, 130, 47, 190, 228, 149, 179, 118, 52, 87, 134, 54, 474, 340, 27, 267, 112, 188, 30, 314, 92, 93, 164, 146, 98, 665, 83, 44, 105, 105, 239, 47, 314, 141, 100, 153, 3475, 93, 76, 95, 2619, 108, 228, 135, 143, 163, 423, 224, 82, 84, 417, 56, 61, 59, 138, 1580, 20, 61, 132, 98, 61, 50, 52, 166, 685, 153, 61, 292, 58, 43, 112, 34, 850, 497, 412, 70, 61, 129, 33, 110, 64, 34, 196, 323, 182, 80, 508, 80, 48, 52, 178, 92, 308, 93, 74, 37, 318, 48, 62, 791, 104, 79, 39, 838, 255, 83, 79, 34, 115, 121, 14, 471, 92, 77, 106, 62, 158, 54, 51, 71, 165, 68, 34, 47, 270, 43, 74, 119, 188, 680, 84, 69, 142, 183, 87, 210, 142, 114, 202, 138, 85, 3078, 85, 57, 162, 55, 103, 414, 262, 68, 45, 54, 206, 376, 63, 157, 131, 53, 80, 66, 48, 39, 178, 45, 87, 39, 60, 508, 912, 83, 63, 33, 101, 54, 73, 240, 77, 89, 81, 60, 75, 83, 64, 39, 28, 180, 350, 126, 120, 48, 67, 674, 191, 79, 80, 143, 122, 64, 2146, 63, 99, 43, 151, 220, 46, 246, 48, 191, 74, 127, 169, 69, 105, 217, 688, 90, 166, 30, 54, 59, 9, 470, 657, 248, 168, 288, 30, 1607, 90, 113, 243, 168, 257, 66, 213, 85, 13, 385, 49, 128, 288, 89, 176, 8, 155, 46, 121, 87, 491, 203, 56, 76, 477, 67, 53, 151, 48, 181, 71, 68, 51, 48, 160, 866, 112, 15, 40, 165, 48, 68, 107, 43, 86, 45, 226, 636, 67, 158, 148, 110, 760, 48, 165, 177, 36, 76, 68, 292, 487, 164, 415, 65, 244, 110, 0, 672, 208, 113, 92, 339, 30, 1331, 250, 40, 987, 91, 134, 89, 79, 136, 47, 92, 47, 59, 114, 355, 282, 85, 320, 25, 82, 74, 61, 109, 184, 95, 231, 32, 1231, 29, 254, 38, 9, 73, 75, 1269, 158, 173, 68, 23, 345, 236, 52, 88, 135, 48, 69, 193, 205, 98, 83, 165, 196, 53, 83, 57, 41, 124, 30, 94, 113, 138, 102, 118, 138, 64, 63, 156, 480, 273, 59, 89, 489, 54, 23, 112, 0, 57, 160, 121, 84, 143, 51, 386, 196, 354, 837, 105, 22, 65, 206, 86, 49, 110, 34, 191, 41, 99, 121, 66, 223, 361, 51, 9, 198, 64, 6864, 77, 108, 80, 113, 80, 462, 86, 166, 107, 40, 167, 543, 61, 97, 79, 191, 464, 52, 91, 317, 480, 207, 106, 637, 102, 62, 179, 447, 110, 152, 153, 316, 38, 79, 645, 59, 271, 76, 53, 209, 124, 187, 236, 118, 345, 137, 113, 80, 308, 56, 1031, 486, 809, 2047, 5917, 33268, 780, 567, 449, 1127, 99, 922, 978, 56, 223, 766, 79, 81, 5779, 91, 261, 84, 132, 121, 1, 20, 210, 478, 49, 113, 467, 48, 116, 47, 65, 1751, 217, 123, 27255, 471, 304, 164, 217, 229, 147, 201, 67, 58, 103, 104, 107, 120, 162, 119, 53, 62, 56, 136, 77, 109, 683, 169, 125, 100, 78, 169, 73, 93, 32, 204, 51, 29, 234, 150, 43, 331, 70, 623, 282, 243, 50, 289, 48, 335, 226, 144, 68, 80, 43, 173, 65, 124, 799, 73, 10, 51, 233, 1217, 73, 277, 97, 178, 140, 45, 100, 1118, 53, 628, 274, 111, 185, 107, 50, 347, 133, 104, 108, 89, 171, 46, 270, 348, 400, 103, 343, 243, 296, 13, 1139, 196, 0, 225, 97, 133, 6853, 126, 127, 632, 79, 239, 93, 123, 258, 74, 74, 83, 68, 34, 528, 210, 99, 1488, 48, 20, 389, 70, 5592, 462, 345, 146, 65, 359, 882, 146, 63, 283, 106, 748, 49, 506, 101, 435, 1207, 48, 711, 353, 222, 1168, 265, 791, 75, 144, 67, 89, 66, 5430, 114, 95, 86, 55, 113, 53, 5694, 310, 155, 49, 48, 55, 80, 30, 1022, 105, 572, 140, 85, 231, 30, 61, 3299, 120, 108, 72, 214, 742, 102, 788, 354, 147, 173, 171, 147, 11405, 4484, 50, 50, 403]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                   SPAM FREQUENCY\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[281, 505, 54, 28, 30, 8, 23, 4, 18, 1, 31, 17, 17, 336, 180, 0, 69, 110, 28, 50, 0, 87, 49, 43, 33, 52, 168, 10, 3, 144, 35, 23, 21, 44, 133, 309, 75, 0, 0, 28, 12, 92, 120, 37, 3, 19, 44, 20, 48, 153, 25, 31, 23, 23, 25, 4, 0, 32, 41, 15, 8, 0, 36, 39, 6, 39, 18, 15, 0, 56, 80, 7, 0, 22, 43, 202, 102, 15, 2, 11, 0, 5, 16, 16, 8, 89, 23, 42, 49, 36, 1, 1, 49, 88, 2, 0, 85, 0, 0, 91, 31, 1, 124, 209, 0, 99, 44, 61, 347, 88, 41, 5, 25, 15, 136, 27, 317, 13, 34, 28, 24, 16, 96, 30, 15, 37, 12, 37, 14, 18, 82, 294, 2, 116, 13, 5, 5, 22, 52, 84, 74, 77, 0, 35, 150, 3, 85, 35, 0, 60, 13, 13, 13, 40, 8, 0, 54, 57, 3, 803, 40, 24, 29, 25, 26, 64, 215, 33, 15, 49, 170, 30, 45, 0, 45, 80, 623, 24, 8, 22, 5165, 63, 3, 0, 0, 9, 29, 10, 21, 55, 20, 474, 63, 36, 0, 18, 16, 8, 7, 66, 48, 5, 49, 10, 3, 9, 5, 15, 64, 15, 5, 1266, 49, 14, 38, 0, 2, 5, 8, 6, 978, 0, 33, 15, 9, 7, 40, 48, 48, 6, 13, 9, 24, 14, 5, 17, 805, 10, 0, 2, 7, 0, 29, 15, 1, 40, 30, 188, 50, 19, 23, 80, 101, 4, 16, 132, 28, 33, 23, 134, 12, 25, 1, 1335, 154, 113, 262, 129, 12, 4, 15, 18, 86, 76, 179, 1, 32, 50, 1, 295, 64, 48, 72, 30, 64, 47, 9, 23, 1, 48, 42, 14, 58, 71, 20, 60, 0, 26, 9, 38, 2, 8, 31, 43, 33, 46, 721, 44, 4, 351, 132, 836, 44, 2, 4, 28, 101, 30, 19, 0, 674, 19, 5, 1, 66, 5, 60, 32, 109, 28, 21, 0, 0, 42, 112, 37, 7, 104, 0, 37, 35, 10, 30, 47, 6, 0, 2, 34, 105, 9, 46, 33, 9, 63, 36, 93, 11, 30, 0, 43, 1, 1, 43, 31, 20, 0, 58, 431, 49, 32, 20, 7, 53, 57, 22, 0, 5, 10, 1, 837, 84, 22, 29, 16, 7, 38, 26, 14, 15, 3, 2, 23, 41, 21, 216, 631, 41, 11, 31, 63, 101, 17, 13, 90, 3, 8, 8, 26, 4, 5, 39, 18, 24, 12, 3, 20, 13, 6, 39, 10, 4, 11, 21, 166, 8, 9, 16, 8, 53, 45, 125, 7, 42, 4, 7, 21, 19, 2, 60, 31, 13, 0, 0, 3, 5, 75, 20, 40, 43, 74, 8, 125, 22, 187, 48, 113, 14, 48, 13, 48, 24, 17, 91, 131, 0, 7, 6, 2, 109, 61, 0, 0, 53, 106, 114, 7, 41, 0, 73, 63, 95, 7, 3, 12, 167, 144, 116, 1, 37, 17, 86, 33, 7, 3, 25, 35, 28, 6, 0, 11, 5, 21, 36, 30, 80, 27, 29, 3, 0, 0, 8, 85, 22, 6, 1, 6, 18, 69, 9, 24, 24, 15, 62, 5, 45, 31, 9, 48, 6, 0, 41, 6, 21, 32, 19, 16, 15, 6, 2, 5, 19, 34, 624, 1, 1, 29, 143, 32, 43, 121, 176, 68, 2, 69, 98, 33, 1, 30, 42, 27, 76, 42, 19, 122, 2, 13, 36, 29, 5, 132, 1, 0, 0, 18, 2, 16, 1, 5, 43, 1, 28, 0, 35, 81, 8, 30, 60, 30, 1, 4, 13, 19, 675, 47, 17, 15, 22, 14, 0, 5, 8, 59, 24, 11, 87, 39, 2, 43, 0, 0, 32, 56, 34, 7, 30, 27, 0, 78, 16, 44, 13, 40, 17, 8, 3, 146, 1, 27, 49, 88, 118, 32, 48, 31, 33, 22, 1, 20, 6, 46, 2, 28, 14, 25, 32, 31, 33, 44, 14, 3, 11, 31, 16, 6, 22, 8, 2, 56, 20, 4, 15, 81, 12, 35, 0, 50, 31, 11, 70, 21, 97, 56, 28, 3, 1, 35, 20, 8, 59, 47, 107, 20, 28, 15, 57, 20, 28, 20, 152, 144, 7, 11, 162, 23, 56, 27, 6, 6, 32, 15, 4, 54, 133, 16, 2595, 5, 3, 45, 137, 1, 11, 40, 15, 3, 147, 2, 4, 50, 34, 6, 510, 51, 6, 6, 35, 38, 1165, 46, 38, 124, 22, 1, 5, 62, 71, 98, 206, 5, 1, 1, 0, 76, 7, 46, 39, 11, 5, 490, 17, 65, 0, 99, 62, 12, 25, 8, 52, 165, 28, 12, 52, 12, 170, 51, 134, 2, 58, 65, 139, 10, 8, 6, 4, 91, 11, 47, 86, 60, 89, 68, 2, 8, 126, 32, 4, 66, 34, 34, 45, 461, 1072, 12, 53, 155, 13, 20, 11, 21, 5, 0, 15, 113, 188, 1, 11, 86, 617, 6, 47, 134, 18, 26, 44, 1, 4, 177, 14, 23, 11, 2, 217, 20, 0, 34, 91, 9, 0, 16, 98, 41, 3, 335, 7, 41, 7, 0, 15, 62, 481, 0, 61, 17, 126, 30, 17, 22, 16, 74, 722, 3, 64, 53, 56, 18, 2, 1, 32, 61, 1, 20, 17, 39, 3088, 128, 82, 27, 40, 101, 98, 98, 21, 46, 13, 4, 6, 22, 20, 6, 34, 136, 136, 28, 3, 593, 8, 22, 5, 40, 4, 9, 50, 96, 8, 32, 122, 166, 12, 18, 10, 70, 236, 0, 7, 5, 278, 28, 247, 44, 52, 88, 8, 13, 0, 33, 38, 0, 2408, 40, 0, 29, 28, 7, 1312, 42, 284, 18, 7, 2, 10, 1, 3, 0, 0, 34, 4, 14, 42, 2, 29, 11, 7, 145, 2, 54, 48, 426, 0, 81, 21, 1, 0, 2, 41, 0, 50, 0, 14, 201, 23, 35, 0, 0, 0, 0, 46, 0, 42, 25, 75, 38, 36, 42, 25, 5, 25, 3, 48, 75, 5, 52, 17, 2, 2, 24, 84, 0, 63, 74, 73, 43, 10, 273, 8, 275, 15, 19, 104, 1, 129, 110, 25, 322, 42, 50, 60, 29, 126, 5, 4, 58, 30, 9, 13, 15, 20, 160, 0, 12, 73, 45, 127, 160, 11, 59, 36, 28, 61, 78, 132, 37, 9, 13, 0, 0, 67, 194, 1, 505, 38, 144, 60, 21, 8, 70, 400, 22, 58, 84, 23, 106, 53, 8, 16, 170, 16, 10, 224, 246, 32, 6, 0, 10, 0, 55, 28, 0, 45, 0, 405, 18, 5, 314, 17, 46, 21, 122, 42, 12, 5, 37, 38, 8, 17, 353, 11, 4, 36, 0, 22, 18, 6, 65, 1, 209, 32, 33, 6, 22, 58, 16, 1, 0, 2, 0, 22, 17, 549, 0, 106, 32, 80, 1, 596, 25, 166, 46, 14, 7, 98, 25, 162, 36, 35, 0, 122, 89, 617, 19, 7, 235, 52, 35, 34, 16, 24, 55, 261, 39, 48, 262, 44, 109, 394, 138, 68, 134, 52, 5, 548, 40, 13, 0, 70, 31, 1120, 55, 4, 57, 95, 42, 5, 2, 4, 472, 149, 33, 7, 21, 9, 1, 1, 71, 4469, 65, 222, 13, 37, 147, 69, 27, 11, 93, 14, 38, 1268, 73, 491, 58, 294, 396, 27, 43, 21, 1, 17, 15, 29, 45, 81, 3, 8, 40, 1245, 295, 39, 112, 65, 35, 73, 261, 84, 30, 1153, 463, 1, 11, 39, 364, 4, 7, 110, 11, 49, 52, 44, 14, 80, 6, 24, 2, 86, 12, 27, 1, 10, 11, 6, 26, 62, 39, 68, 9, 17, 14, 57, 36, 1, 1, 0, 61, 43, 22, 38, 5, 9, 298, 194, 58, 66, 3, 21, 49, 54, 78, 2, 11, 4, 2, 105, 12, 23, 0, 3, 60, 17, 51, 22, 46, 3, 481, 23, 16, 36, 24, 9, 40, 6, 31, 46, 59, 11, 61, 2, 62, 4, 31, 2, 82, 51, 44, 5, 0, 36, 8, 11, 9, 33, 14, 5, 21, 52, 73, 5, 9, 16, 205, 140, 17, 20, 26, 20, 42, 62, 5, 113, 12, 25, 36, 5, 64, 7, 35, 17, 121, 66, 149, 0, 124, 35, 1, 24, 36, 207, 108, 6, 9, 42, 42, 18, 14, 29, 23, 10, 66, 177, 100, 25, 35, 6, 51, 22, 1, 8, 56, 22, 28, 2, 53, 4, 58, 0, 22, 51, 28, 27, 8, 12, 30, 93, 55, 17, 0, 0, 26, 106, 47, 10, 98, 16, 114, 139, 79, 37, 16, 19, 269, 248, 93, 16, 48, 26, 4, 21, 8, 21, 6, 15, 19, 27, 5, 34, 111, 8, 30, 62, 17, 12, 3, 36, 7, 15, 51, 11, 13, 69, 3, 116, 115, 123, 339, 8, 88, 25, 17, 58, 12, 13, 30, 50, 43, 14, 45, 2, 9, 18, 13, 61, 26, 30, 2, 71, 0, 11, 3, 25, 60, 112, 3, 35, 67, 28, 16, 33, 56, 78, 0, 1, 2, 166, 28, 103, 33, 13, 3, 4, 7, 4, 17, 9, 48, 45, 39, 128, 79, 12, 3, 54, 4, 233, 73, 12, 10, 6, 0, 1, 26, 9, 3, 6, 167, 43, 71, 11, 49, 122, 218, 268, 3, 34, 11, 5, 20, 20, 20, 17, 84, 31, 14, 276, 41, 70, 17, 6, 135, 4, 7, 7, 23, 16, 40, 163, 164, 15, 50, 2, 71, 0, 82, 28, 0, 0, 57, 45, 57, 0, 53, 8, 153, 56, 14, 26, 23, 15, 8, 20, 51, 90, 0, 65, 55, 11, 262, 96, 28, 32, 40, 0, 5, 57, 1, 58, 269, 62, 365, 33, 53, 19, 30, 152, 40, 44, 1, 26, 44, 43, 11, 35, 25, 26, 30, 7, 0, 0, 2, 126, 44, 10, 12, 12, 31, 2, 36, 2, 10, 3, 4, 49, 15, 9, 49, 43, 1, 166, 32, 47, 119, 36, 231, 75, 98, 0, 32, 16, 66, 6, 22, 11, 1, 53, 0, 171, 76, 57, 6, 27, 29, 9, 28, 27, 12, 44, 24, 1, 5, 9, 6, 90, 4, 2, 1278, 97, 3, 24, 124, 56, 155, 7, 3, 8, 72, 1, 9, 7, 0, 1, 16, 88, 5, 0, 79, 172, 65, 7, 175, 24, 39, 22, 11, 0, 8, 0, 0, 23, 42, 60, 6, 13, 14, 33, 158, 1, 19, 32, 42, 71, 54, 12, 2, 7, 51, 60, 225, 90, 55, 1503, 7057, 243, 170, 135, 220, 33, 274, 249, 92, 64, 52, 47, 49, 2311, 9, 115, 22, 25, 5, 52, 61, 89, 206, 9, 0, 15, 13, 0, 4, 3, 440, 54, 16, 6613, 191, 25, 14, 1, 7, 2, 72, 15, 24, 43, 82, 0, 1, 145, 9, 9, 1, 29, 71, 5, 5, 50, 27, 73, 42, 91, 15, 8, 38, 46, 3, 30, 29, 48, 9, 97, 19, 29, 95, 8, 76, 14, 56, 7, 117, 25, 7, 14, 8, 36, 10, 69, 2, 10, 8, 55, 90, 48, 305, 6, 33, 18, 0, 46, 27, 19, 426, 53, 238, 66, 7, 112, 34, 14, 92, 4, 0, 3, 5, 10, 38, 4, 92, 2, 12, 0, 119, 80, 67, 156, 48, 148, 6, 26, 58, 0, 3, 24, 134, 13, 0, 0, 20, 2, 15, 4, 0, 50, 15, 272, 30, 8, 384, 9, 65, 215, 15, 1360, 0, 181, 383, 2, 7, 96, 2, 12, 67, 63, 124, 8, 93, 17, 0, 303, 7, 203, 110, 16, 279, 90, 251, 20, 17, 7, 74, 23, 1193, 1, 3, 17, 62, 141, 4, 1424, 268, 155, 27, 5, 2, 28, 40, 201, 15, 70, 61, 1, 150, 86, 48, 220, 64, 23, 3, 0, 328, 35, 135, 130, 36, 0, 49, 13, 4079, 3093, 37, 73, 0]\n"
     ]
    }
   ],
   "source": [
    "# I calculated here , the frequency of a word in HAM / SPAM mail only.\n",
    "\n",
    "def sum_of_frequency_each_uniq(frekans_icin_array,ham_spam_only):\n",
    "    sirali_frekans = list()\n",
    "    for i in range(len(unique_words)):\n",
    "        frekans = 0\n",
    "        for j in range(len(ham_spam_only)):\n",
    "            frekans += frekans_icin_array[j][i]\n",
    "        sirali_frekans.append(frekans)\n",
    "    return sirali_frekans\n",
    "\n",
    "\n",
    "ham_frequency_list = sum_of_frequency_each_uniq(hamlarin_label_arrayi,ham_only)\n",
    "\n",
    "print(\"                   HAM FREQUENCY\")\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print(ham_frequency_list)\n",
    "\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"                   SPAM FREQUENCY\")\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "spam_frequency_list = sum_of_frequency_each_uniq(spamlarin_label_arrayi,spam_only)\n",
    "\n",
    "print(spam_frequency_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caba9a88",
   "metadata": {},
   "source": [
    "                             *********************    PART 1   *******************\n",
    "\n",
    "I can give simple 3 example words...\n",
    "\n",
    "\"2000\"    3860 times in ham   |  5 times in spam\n",
    "\"2001\"    2527 times in ham   |  23 times in spam\n",
    "\"zimin\"   403 times in ham    |  0 times in spam\n",
    "\n",
    "Yes, it is quite convenient to apply this algorithm to data processing. I will easily calculate what type of text it is by calculating conditional probabilities.\n",
    "\n",
    "I've already thrown the highest frequency words that are only in spam and raw into a list. from here it is also very simple that \"2000\" named word's frequency is 3860 in ham (but in spam only 5 times),\"2001\"  named word's frequency is 2527 in ham(but in spam only 23 times) and \"zimin\" named word's frequency is 403 in ham (but in spam only 0 times) seem to be quite effective when making predictions. \n",
    "\n",
    "As a result, such decisive words can be easily seen even by looking at the list.\n",
    "\n",
    "------------------------ Stop Words---------------------------------\n",
    "It's not a good thing that a word passes too often on both sides . There are english words called stop_words. (a , an, to , the , one ,and ,with... as such ) we can say that the most ineffective words for the three of these words that occur most often are.\n",
    "\n",
    "                             *********************    PART 1   *******************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f5f237a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROBABLITY FOR HAM WORDS : \n",
      "\n",
      "[0.0014608137546033462, 0.00041562435581010535, 0.0015521842564168277, 0.0011410169982561606, 0.001135445626194363, 0.0013438149413055954, 0.0009437904272685234, 7.799920886516722e-05, 0.0007565923259921221, 9.248477622584114e-05, 0.0007465638562808863, 0.0010507607708550384, 0.0009460189760932424, 0.0019600086913404164, 0.00015154132008089632, 8.468485533932441e-05, 0.0014819849684381773, 0.0013226437274707643, 0.00041673863022246487, 0.0005370802667572943, 0.00012034163653482944, 0.000771077893352796, 3.788533002022408e-05, 0.0006173080244471806, 0.0005638228526539231, 0.0005270517970460586, 0.0006284507685707759, 7.131356239101004e-05, 0.00016379833861685116, 0.0008011633024865033, 6.462791591685285e-05, 0.004302213506120152, 0.0028168857144448963, 6.351364150449331e-05, 1.0028469711235786e-05, 6.6856464741571905e-06, 0.00043345274640785785, 0.00012479873418426755, 0.00016045551537977257, 0.00044013839288201503, 0.0005081091320359465, 0.000454623960242689, 0.0004936235646752726, 2.1171213834831103e-05, 0.00017382680832808695, 0.0003821961234393194, 0.0005125662296853846, 0.00046799525319100334, 0.0005081091320359465, 0.0013237580018831238]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PROBABLITY FOR SPAM WORDS : \n",
      "\n",
      "[0.00123049533982616, 0.0022079100778441023, 0.00023999022585261982, 0.00012654030090410864, 0.00013526721820784026, 3.927112786679233e-05, 0.00010472300764477956, 2.1817293259329074e-05, 8.290571438545049e-05, 8.72691730373163e-06, 0.00013963067685970608, 7.854225573358467e-05, 7.854225573358467e-05, 0.0014704855656787795, 0.0007897860159877125, 4.363458651865815e-06, 0.000305442105630607, 0.00048434391035710543, 0.00012654030090410864, 0.00022253639124515656, 4.363458651865815e-06, 0.0003839843613641917, 0.00021817293259329074, 0.00019199218068209585, 0.00014835759416343772, 0.00023126330854888818, 0.0007374245121653227, 4.799804517052396e-05, 1.745383460746326e-05, 0.0006327015045205431, 0.00015708451146716933, 0.00010472300764477956, 9.599609034104792e-05, 0.00019635563933396167, 0.0005847034593500192, 0.0013526721820784026, 0.00033162285754180195, 4.363458651865815e-06, 4.363458651865815e-06, 0.00012654030090410864, 5.6724962474255596e-05, 0.00040580165462352077, 0.0005279784968757636, 0.00016581142877090097, 1.745383460746326e-05, 8.72691730373163e-05, 0.00019635563933396167, 9.163263168918212e-05, 0.00021380947394142492, 0.0006719726323873355]\n"
     ]
    }
   ],
   "source": [
    "# I calculated here , bayes of each word. ( seperately for both ham and spam )\n",
    "\n",
    "def cond_probablity(param1,param2):\n",
    "    conditional_list = list()\n",
    "    for i in range(len(unique_words)):\n",
    "        cond_prob = (param2[i] + 1) / (param1 + len(unique_words))\n",
    "        conditional_list.append(cond_prob)\n",
    "\n",
    "    return conditional_list\n",
    "\n",
    "#                              the formula\n",
    "\n",
    "#        (        counting of \"x\" words in spam/ham + 1           )\n",
    "#        --------------------------------------------------------------\n",
    "#        (When row is spam/ham , count of all words + Unique word count)\n",
    "\n",
    "\n",
    "\n",
    "print(\"PROBABLITY FOR HAM WORDS : \")\n",
    "print()\n",
    "ham_con_prob_list = cond_probablity(ham_all_words_count(ham_only),ham_frequency_list)\n",
    "print(ham_con_prob_list[:50])               # i printed only 50 element because so that you can see more comfortably\n",
    "\n",
    "\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"PROBABLITY FOR SPAM WORDS : \")\n",
    "print()\n",
    "spam_con_prob_list = cond_probablity(spam_all_words_count(spam_only),spam_frequency_list)\n",
    "print(spam_con_prob_list[:50])              # i printed only 50 element here so that you can see more comfortably\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57ee836e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just some for example  :  0.0010273610081954882\n"
     ]
    }
   ],
   "source": [
    "# I transferred the words as KEY and the possibilities as VALUE to the DICTIONARY because it was difficult to access.\n",
    "\n",
    "def list_to_dict(param1, param2):\n",
    "\n",
    "    return dict(list(zip(param1, param2)))\n",
    "\n",
    "ham_sozluk = list_to_dict(unique_words, ham_con_prob_list)\n",
    "\n",
    "spam_sozluk = list_to_dict(unique_words, spam_con_prob_list)\n",
    "\n",
    "ham_sozluk_tfidf = list_to_dict(ham_tf_unique, ham_tf_olasilik)\n",
    "\n",
    "spam_sozluk_tfidf = list_to_dict(spam_tf_unique, spam_tf_olasilik)\n",
    "\n",
    "print(\"Just some for example  : \" ,ham_sozluk[\"his\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c3c6e6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#                                                MODEL \n",
    "#\n",
    "#                         Here I am sending test data to the model i have built\n",
    "\n",
    "\n",
    "# I have broken down the test data into words for the test. (row by row)\n",
    "\n",
    "def test_row_split():\n",
    "    sentences_word_list = list()\n",
    "    \n",
    "    for i in x_test_np:\n",
    "        sentences_word_list.append(i.split(\" \"))\n",
    "    \n",
    "    return sentences_word_list\n",
    "        \n",
    "\n",
    "splitted_test_mails = test_row_split()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# To implement Bayes, I added the conditional probabilities logarithmically that I calculated earlier.\n",
    "# I've found the last possibility. So I can calculate the accuracy by comparing it with its real value (spam or raw?).\n",
    "\n",
    "def bayes(p_x , x_sozluk):\n",
    "    all_bayes = list()\n",
    "    for mail in splitted_test_mails:\n",
    "        each_bayes = math.log(p_x)\n",
    "        for word in mail[1:]:\n",
    "            if word not in x_sozluk:\n",
    "                each_bayes*=1\n",
    "            else:\n",
    "                each_bayes += math.log(x_sozluk['{}'.format(word)])\n",
    "        all_bayes.append(each_bayes)\n",
    "    return all_bayes\n",
    "           \n",
    "    \n",
    "   #  with count vectorizer \n",
    "    \n",
    "ham_bayes = bayes(p_ham,ham_sozluk)\n",
    "spam_bayes = bayes(p_spam,spam_sozluk)\n",
    "\n",
    "    \n",
    "   #  with tf-idf  \n",
    "   \n",
    "ham_bayes_tfidf = bayes(p_ham, ham_sozluk_tfidf)\n",
    "spam_bayes_tfidf = bayes(p_spam, spam_sozluk_tfidf)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    # I counted here true predictions . And i sent a list these . (for library of metrics )   \n",
    "\n",
    "def predict(ham, spam):\n",
    "    prediction_list = list()\n",
    "\n",
    "    for i in range(len(x_test_np)):\n",
    "        if ham[i] > spam[i]:\n",
    "            prediction_list.append(0)\n",
    "        else:\n",
    "            prediction_list.append(1)\n",
    "\n",
    "    return prediction_list\n",
    "\n",
    "\n",
    "list_of_predict = predict(ham_bayes, spam_bayes)\n",
    "\n",
    "\n",
    "list_of_predict_tfidf = predict(ham_bayes_tfidf,spam_bayes_tfidf)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### CAUTION ###### \n",
    "# If you want to see prediction label and real value , you can remove comment line(3) BELOW and run it .\n",
    "\n",
    "\n",
    "# print(\"prediction | real value\")\n",
    "# for j in range(len(y_test_np)):\n",
    "#     print(list_of_predict[j] , \"         |       \" , y_test_np[j])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b53e70e4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PART 4 \n",
      "\n",
      "Count Vectorizer\n",
      "\n",
      "Accuracy Score :    ½ 97.99301919720767\n",
      "Precision Score :   % 94.73684210526315\n",
      "Recall Score :   % 96.55172413793103\n",
      "F1 Score :   % 95.63567362428843\n",
      "\n",
      "\n",
      "TF-IDF\n",
      "\n",
      "Accuracy Score :    ½ 91.36125654450262\n",
      "Precision Score :   % 76.47058823529412\n",
      "Recall Score :   % 89.65517241379311\n",
      "F1 Score :   % 82.53968253968254\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------- PART 4 ----------------------------------      for UNIGRAM\n",
    "\n",
    "# Accuracy  -  Precision  -  Recall  -  F1Score \n",
    "\n",
    "print(\"PART 4 \\n\")\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# from sklearn.metrics import recall_score\n",
    "def metrics(y_testt, predict_lists):\n",
    "    accuracyy = accuracy_score(y_testt, predict_lists)\n",
    "\n",
    "    print(\"Accuracy Score :    ½\", accuracyy * 100)\n",
    "\n",
    "    precision = precision_score(y_testt, predict_lists)\n",
    "\n",
    "    print(\"Precision Score :   %\", precision * 100)\n",
    "\n",
    "    recall = recall_score(y_testt, predict_lists)\n",
    "\n",
    "    print(\"Recall Score :   %\", recall * 100)\n",
    "\n",
    "    f1 = f1_score(y_testt, predict_lists)\n",
    "\n",
    "    print(\"F1 Score :   %\", f1 * 100)\n",
    "    \n",
    "print(\"Count Vectorizer\")\n",
    "print()\n",
    "metrics(y_test_np, list_of_predict)\n",
    "print()\n",
    "print()\n",
    "print(\"TF-IDF\")\n",
    "print()\n",
    "metrics(y_test_np,list_of_predict_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c783f56",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PART 3 \n",
      "\n",
      "List the 10 words whose presence most strongly predicts that the mail is ham.\n",
      "Useful Words For Ham : \n",
      " ['100038', 'approve', 'bambos', 'behind', 'copyright', 'courses', 'cunningham', 'degree', 'described', 'difficulties']\n",
      "\n",
      "\n",
      "List the 10 words whose absence most strongly predicts that the mail is ham.\n",
      "Useless Words For Ham : \n",
      " ['00', '000', '0011', '01', '02', '03', '04', '05', '0500', '06']\n",
      "\n",
      "\n",
      "List the 10 words whose presence most strongly predicts that the mail is spam.\n",
      "Useful Words For Spam : \n",
      " ['1995', '218', '55', '58', '69', 'accepted', 'across', 'actually', 'advises', 'amonq']\n",
      "\n",
      "\n",
      "List the 10 words whose absence most strongly predicts that the mail is spam.\n",
      "Useless Words For Spam : \n",
      "  ['00', '000', '0000', '01', '02', '03', '05', '06', '07', '10']\n",
      "\n",
      "\n",
      "\n",
      "I showed here English Stop Words \n",
      "\n",
      "frozenset({'most', 'becoming', 'yet', 'anywhere', 'herein', 'often', 'afterwards', 'here', 'hasnt', 'only', 'too', 'eight', 'part', 'else', 'per', 'mill', 'found', 'amount', 'then', 'cant', 'please', 'itself', 'full', 'move', 'another', 'least', 'always', 'should', 'take', 'we', 'my', 'against', 'any', 'at', 'own', 'them', 'rather', 'who', 'several', 'for', 'on', 'other', 'noone', 'eleven', 'six', 'within', 'whose', 'forty', 'mine', 'with', 'our', 'enough', 'detail', 'their', 'also', 'which', 'ours', 'hundred', 'above', 'much', 'me', 'until', 'could', 'before', 'more', 'therein', 'wherein', 'sometimes', 'under', 'through', 'co', 'from', 'inc', 'system', 'cannot', 'last', 'be', 'whereby', 'over', 'behind', 'that', 'must', 'hereafter', 'around', 'front', 'without', 'alone', 'up', 'are', 'may', 'describe', 'those', 'hers', 'during', 'no', 'two', 'see', 'back', 'amoungst', 'put', 'while', 'might', 'became', 'except', 'somewhere', 'yourselves', 'therefore', 'has', 'nowhere', 'empty', 'can', 'an', 'third', 'almost', 'perhaps', 'its', 'it', 'anything', 'or', 'de', 'others', 'still', 'both', 'give', 'well', 'how', 'thin', 'if', 'nevertheless', 'none', 're', 'whereafter', 'these', 'because', 'some', 'name', 'someone', 'never', 'do', 'seem', 'anyone', 'whereas', 'first', 'yours', 'call', 'very', 'in', 'and', 'etc', 'three', 'you', 'all', 'he', 'beside', 'get', 'either', 'us', 'a', 'next', 'everywhere', 'after', 'sincere', 'un', 'toward', 'done', 'when', 'across', 'of', 'along', 'why', 'upon', 'even', 'herself', 'towards', 'become', 'everything', 'seeming', 'beyond', 'anyhow', 'keep', 'would', 'his', 'every', 'yourself', 'find', 'less', 'already', 'was', 'the', 'your', 'few', 'though', 'been', 'thus', 'am', 'namely', 'neither', 'among', 'whether', 'themselves', 'side', 'beforehand', 'made', 'twelve', 'such', 'whom', 'everyone', 'meanwhile', 'elsewhere', 'off', 'interest', 'again', 'this', 'than', 'as', 'between', 'together', 'seemed', 'out', 'each', 'becomes', 'mostly', 'show', 'although', 'latterly', 'whereupon', 'whole', 'fifty', 'where', 'whenever', 'whence', 'hence', 'myself', 'twenty', 'somehow', 'ten', 'they', 'what', 'nor', 'once', 'had', 'onto', 'being', 'now', 'eg', 'thick', 'nothing', 'but', 'formerly', 'himself', 'five', 'thru', 'sixty', 'throughout', 'otherwise', 'to', 'four', 'bill', 'indeed', 'is', 'latter', 'not', 'besides', 'via', 'whatever', 'however', 'bottom', 'fifteen', 'fire', 'hereupon', 'further', 'ltd', 'so', 'sometime', 'top', 'she', 'anyway', 'down', 'one', 'him', 'will', 'thence', 'since', 'i', 'fill', 'whither', 'couldnt', 'hereby', 'wherever', 'nobody', 'below', 'ourselves', 'same', 'her', 'former', 'ie', 'many', 'something', 'thereby', 'by', 'serious', 'seems', 'nine', 'amongst', 'there', 'into', 'moreover', 'con', 'thereafter', 'have', 'cry', 'due', 'ever', 'go', 'were', 'thereupon', 'whoever', 'about'})\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------   PART 3  ---------------------------------------------\n",
    "# \n",
    "\n",
    "#   I have listed the words with the highest probability when finding these words. (with sorted()).\n",
    "#   Then I kept the indexes of these values in a list and called the words that are the owners of these possibilities.\n",
    "#   Here we can easily see that meaningless numbers have reduced the state of guessing to \"Ham\" .\n",
    "#   In the same way, the presence of some words was effective in determining the class as SPAM / HAM\n",
    "\n",
    "print(\"PART 3 \\n\")\n",
    "\n",
    "yararli_ham = list()\n",
    "for i in ham_tf_unique:\n",
    "    if ham_sozluk_tfidf.get(i) >= ham_tf_yararli:\n",
    "        yararli_ham.append(i)\n",
    "        \n",
    "print(\"List the 10 words whose presence most strongly predicts that the mail is ham.\")\n",
    "print(\"Useful Words For Ham : \\n\", yararli_ham[:10])\n",
    "print()\n",
    "print()\n",
    "\n",
    "yararsiz_ham = list()\n",
    "for i in ham_tf_unique:\n",
    "    if ham_sozluk_tfidf.get(i) >= ham_tf_yararsiz:\n",
    "        yararsiz_ham.append(i)\n",
    "        \n",
    "print(\"List the 10 words whose absence most strongly predicts that the mail is ham.\")\n",
    "print(\"Useless Words For Ham : \\n\",yararsiz_ham[:10])\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "yararli_spam = list()\n",
    "for i in spam_tf_unique:\n",
    "    if spam_sozluk_tfidf.get(i) >= spam_tf_yararli:\n",
    "        yararli_spam.append(i)\n",
    "        \n",
    "print(\"List the 10 words whose presence most strongly predicts that the mail is spam.\")\n",
    "print(\"Useful Words For Spam : \\n\",yararli_spam[:10])\n",
    "print()\n",
    "print()\n",
    "\n",
    "yararsiz_spam = list()\n",
    "for i in spam_tf_unique:\n",
    "    if spam_sozluk_tfidf.get(i) >= spam_tf_yararsiz:\n",
    "        yararsiz_spam.append(i)\n",
    "        \n",
    "print(\"List the 10 words whose absence most strongly predicts that the mail is spam.\")\n",
    "print(\"Useless Words For Spam : \\n \",yararsiz_spam[:10])\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"I showed here English Stop Words \\n\")\n",
    "print(ENGLISH_STOP_WORDS)\n",
    "\n",
    "#   The most commonly used words in English that I mention at the beginning are stop_words, such as conjunctions, numbers.\n",
    "# I have listed these words below . If we remove these words from \"bag_of_words\",\n",
    "# our accuracy value will increase significantly. Because the MOST BASIC LOGIC of this classification is that there \n",
    "# is a lot of difference in word frequencies. In other words, if the frequency of the same word in HAM \n",
    "# and SPAM is close to each other, it will not be of much use to us at the prediction stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "182a50ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAG OF WORDS FOR BIGRAM\n",
      "['00 am', '00 pm', '01 2000', '01 2001', '01 pm', '02 2000', '02 2001', '04 2001', '05 01', '05 2000', '06 2000', '07 2000', '08 2000', '09 2000', '10 00', '10 000', '10 2000', '10 30', '10 am', '10 pm', '1092 fax', '11 00', '11 2000', '11 2001', '11 30', '11 am', '12 00', '12 2000', '12 pm', '14 2000', '14 pm', '1400 smith', '15 2000', '16 2000', '16 2001', '17 2000', '18 2000', '19 th', '20 2000', '2000 01', '2000 02', '2000 03', '2000 04', '2000 05', '2000 06', '2000 07', '2000 08', '2000 09', '2000 10', '2000 11', '2000 12', '2001 01', '2001 02', '2001 03', '2001 04', '2001 05', '2001 06', '2001 07', '2001 08', '2001 09', '2001 10', '2001 11', '2001 12', '21 2000', '22 2000', '23 2000', '23 2001', '24 2000', '25 2000', '254 710', '26 2000', '27 2000', '28 2000', '29 2000', '30 2000', '30 2001', '30 am', '30 pm', '31 2000', '31 pm', '39 pm', '44 20', '4473 office', '45 pm', '47 am', '512 471', '52 am', '710 1092', '710 4473', '713 345', '713 348', '713 646', '713 853', '76798 254', '853 3848', '853 5290', '98004 waco', 'ability to', 'able to', 'about it', 'about the', 'about this', 'about your', 'access to', 'according to', 'addition to', 'additional information', 'address is', 'administrative coordinator', 'advantage of', 'advertisement and', 'after the', 'again for', 'agenda for', 'alex huang', 'all of', 'all the', 'all your', 'along with', 'also be', 'am attaching', 'am forwarding', 'am in', 'am looking', 'am not', 'am please', 'am sending', 'am to', 'am very', 'am vince', 'am writing', 'america corp', 'among the', 'amount of', 'an email', 'an interview', 'an mail', 'an offer', 'an opportunity', 'and all', 'and also', 'and am', 'and an', 'and any', 'and are', 'and can', 'and enron', 'and financial', 'and for', 'and get', 'and has', 'and have', 'and he', 'and his', 'and hope', 'and how', 'and if', 'and in', 'and is', 'and it', 'and its', 'and let', 'and look', 'and make', 'and many', 'and may', 'and money', 'and more', 'and my', 'and new', 'and not', 'and or', 'and other', 'and our', 'and research', 'and risk', 'and see', 'and send', 'and that', 'and the', 'and their', 'and then', 'and there', 'and they', 'and this', 'and to', 'and vince', 'and was', 'and we', 'and web', 'and what', 'and will', 'and would', 'and you', 'and your', 'any of', 'any other', 'any questions', 'any time', 'aol com', 'apologize for', 'appreciate it', 'appreciate your', 'are available', 'are currently', 'are going', 'are in', 'are interested', 'are just', 'are looking', 'are not', 'are now', 'are still', 'are the', 'are very', 'are working', 'are you', 'area of', 'around the', 'as an', 'as follows', 'as it', 'as of', 'as part', 'as possible', 'as result', 'as soon', 'as the', 'as they', 'as to', 'as we', 'as well', 'as you', 'ask you', 'asked me', 'at 00', 'at 10', 'at 11', 'at 30', 'at 713', 'at all', 'at austin', 'at enron', 'at http', 'at least', 'at our', 'at stanford', 'at the', 'at this', 'at your', 'attached file', 'attached is', 'attached please', 'attend the', 'available for', 'available to', 'aware of', 'away from', 'back from', 'back in', 'back to', 'based on', 'baylor edu', 'baylor university', 'be able', 'be an', 'be available', 'be glad', 'be good', 'be great', 'be happy', 'be held', 'be in', 'be interested', 'be made', 'be of', 'be on', 'be out', 'be removed', 'be the', 'be to', 'be used', 'be very', 'because of', 'because the', 'because you', 'before the', 'believe that', 'below for', 'best regards', 'between the', 'boost your', 'both the', 'box 98004', 'business and', 'business days', 'but it', 'but not', 'but the', 'but we', 'by enron', 'by shirley', 'by stinson', 'by the', 'by vince', 'call me', 'call you', 'can also', 'can be', 'can do', 'can get', 'can give', 'can help', 'can make', 'can see', 'can send', 'can use', 'can we', 'can you', 'carr collins', 'case you', 'cc shirley', 'cc subject', 'cc vince', 'cell phone', 'chair in', 'chance to', 'christie patrick', 'click here', 'click on', 'collins chair', 'com and', 'com cc', 'com mailto', 'com on', 'com or', 'com sent', 'com subject', 'com to', 'com with', 'com wrote', 'come to', 'coming to', 'communications cc', 'communications enron', 'communications on', 'company and', 'company to', 'complete the', 'conference call', 'conference in', 'confidential and', 'contact information', 'contact me', 'contact the', 'contact you', 'contained in', 'content type', 'continue to', 'coordinator enron', 'copies of', 'copy of', 'corp enron', 'corp from', 'cost of', 'could be', 'could not', 'could you', 'couple of', 'credit risk', 'crenshaw administrative', 'crenshaw enron', 'crenshaw hou', 'dale surbey', 'day to', 'dear dr', 'dear mr', 'dear vince', 'decided to', 'department baylor', 'department of', 'details of', 'development enron', 'development of', 'did not', 'director of', 'director research', 'discuss the', 'discussions with', 'do it', 'do not', 'do so', 'do that', 'do the', 'do this', 'do you', 'does not', 'don have', 'don know', 'don want', 'dr kaminski', 'due to', 'during the', 'each of', 'easy to', 'ect cc', 'ect ect', 'ect enron', 'ect mike', 'ect on', 'ect shirley', 'ect stinson', 'ect subject', 'ect vasant', 'ect vince', 'edu cc', 'edu html', 'edu subject', 'edu web', 'ees ees', 'email address', 'email is', 'email to', 'end of', 'energy derivatives', 'energy industry', 'energy markets', 'engineering and', 'enron and', 'enron broadband', 'enron capital', 'enron cc', 'enron com', 'enron communications', 'enron corp', 'enron development', 'enron enron', 'enron enronxgate', 'enron in', 'enron is', 'enron north', 'enron on', 'enron research', 'enron subject', 'enron to', 'enron vince', 'enron would', 'enronxgate on', 'ensure that', 'experience in', 'fact that', 'fax 713', 'fax martin', 'feel free', 'feel that', 'few days', 'few weeks', 'fill out', 'finance and', 'finance department', 'finance finance', 'find attached', 'find out', 'find the', 'focus on', 'focused on', 'follow up', 'following the', 'for all', 'for an', 'for any', 'for both', 'for dinner', 'for each', 'for energy', 'for enron', 'for example', 'for free', 'for him', 'for his', 'for information', 'for it', 'for me', 'for more', 'for my', 'for new', 'for our', 'for power', 'for some', 'for that', 'for the', 'for their', 'for this', 'for us', 'for you', 'for your', 'forward to', 'forwarded by', 'free to', 'from enron', 'from our', 'from the', 'from this', 'from vince', 'from you', 'from your', 'gas and', 'get back', 'get in', 'get it', 'get the', 'get this', 'get your', 'gibner enron', 'gibner hou', 'give me', 'give you', 'given the', 'glad to', 'go ahead', 'go to', 'going to', 'good morning', 'graduate school', 'grant masson', 'group and', 'group is', 'group of', 'group to', 'group will', 'had to', 'happy to', 'has already', 'has been', 'has the', 'have already', 'have an', 'have any', 'have attached', 'have been', 'have done', 'have great', 'have had', 'have look', 'have made', 'have not', 'have received', 'have some', 'have the', 'have to', 'have you', 'have your', 'he can', 'he has', 'he is', 'he was', 'he will', 'he would', 'head of', 'hear from', 'hearing from', 'hello vince', 'help you', 'here and', 'here are', 'here at', 'here for', 'here http', 'here in', 'here is', 'here to', 'here you', 'hesitate to', 'hi vince', 'him to', 'home html', 'hope that', 'hope to', 'hope you', 'hou ect', 'hou ees', 'houston and', 'houston tx', 'how are', 'how much', 'how the', 'how to', 'how you', 'hsb baylor', 'html martinj', 'http hsb', 'http www', 'idea of', 'if any', 'if can', 'if he', 'if it', 'if not', 'if possible', 'if so', 'if the', 'if there', 'if they', 'if this', 'if we', 'if you', 'important to', 'in addition', 'in advance', 'in all', 'in an', 'in any', 'in case', 'in enron', 'in error', 'in fact', 'in finance', 'in his', 'in houston', 'in london', 'in mind', 'in my', 'in new', 'in one', 'in order', 'in our', 'in particular', 'in some', 'in such', 'in that', 'in the', 'in their', 'in this', 'in to', 'in touch', 'in which', 'in your', 'included in', 'inform you', 'information about', 'information and', 'information from', 'information in', 'information is', 'information on', 'information please', 'information to', 'interest in', 'interest to', 'interested in', 'interview with', 'into the', 'into your', 'invitation to', 'invite you', 'involved in', 'is also', 'is an', 'is as', 'is available', 'is being', 'is confidential', 'is currently', 'is fine', 'is for', 'is going', 'is good', 'is important', 'is in', 'is it', 'is more', 'is my', 'is no', 'is not', 'is now', 'is on', 'is one', 'is still', 'is that', 'is the', 'is there', 'is this', 'is to', 'is very', 'is what', 'is your', 'it and', 'it can', 'it for', 'it has', 'it in', 'it is', 'it may', 'it right', 'it seems', 'it takes', 'it the', 'it to', 'it was', 'it will', 'it with', 'it would', 'jeff shankman', 'john martin', 'join us', 'jones graduate', 'just to', 'just wanted', 'kaminski cc', 'kaminski ect', 'kaminski enron', 'kaminski hou', 'kaminski managing', 'kaminski vince', 'kevin kindall', 'kevin moore', 'kind of', 'kind regards', 'know about', 'know how', 'know if', 'know thanks', 'know that', 'know the', 'know what', 'know when', 'know your', 'krishnarao hou', 'last week', 'last year', 'learn more', 'less than', 'let me', 'let us', 'let you', 'level of', 'like the', 'like to', 'likely to', 'link below', 'list of', 'list please', 'listed below', 'll be', 'logo and', 'lon ect', 'long term', 'look at', 'look forward', 'looking at', 'looking for', 'looking forward', 'lot of', 'lu hou', 'mail address', 'mail message', 'mail to', 'mailing list', 'mailto vince', 'make it', 'make sure', 'make the', 'make you', 'make your', 'management and', 'management rice', 'management system', 'managing director', 'many of', 'many thanks', 'markets and', 'martin baylor', 'martin carr', 'martin lin', 'martinj home', 'masson hou', 'maureen raymond', 'may be', 'may have', 'may need', 'may not', 'me an', 'me and', 'me as', 'me at', 'me call', 'me if', 'me in', 'me know', 'me on', 'me that', 'me the', 'me to', 'me with', 'meet with', 'meet you', 'meeting on', 'meeting with', 'meeting you', 'member of', 'members of', 'message and', 'message from', 'message id', 'message is', 'message to', 'might be', 'might have', 'mike roberts', 'mime version', 'model and', 'model for', 'molly magee', 'monte carlo', 'moore hou', 'more about', 'more details', 'more information', 'more than', 'most of', 'mr kaminski', 'much for', 'much more', 'must be', 'my assistant', 'my group', 'my name', 'my resume', 'na enron', 'name is', 'natural gas', 'necessary to', 'need for', 'need to', 'needs to', 'new year', 'new york', 'next few', 'next week', 'no longer', 'no one', 'no problem', 'north america', 'north american', 'not be', 'not have', 'not hesitate', 'not interested', 'not reply', 'not sure', 'not the', 'not to', 'not wish', 'note that', 'notify the', 'number is', 'number of', 'of all', 'of an', 'of any', 'of business', 'of course', 'of energy', 'of enron', 'of finance', 'of his', 'of industrial', 'of interest', 'of its', 'of management', 'of my', 'of new', 'of our', 'of people', 'of research', 'of risk', 'of some', 'of texas', 'of the', 'of their', 'of them', 'of these', 'of this', 'of time', 'of us', 'of what', 'of you', 'of your', 'off the', 'office 254', 'on 01', 'on 02', 'on 03', 'on 04', 'on 05', 'on 06', 'on 07', 'on 08', 'on 09', 'on 10', 'on 11', 'on 12', 'on energy', 'on friday', 'on how', 'on line', 'on may', 'on monday', 'on my', 'on our', 'on the', 'on this', 'on thursday', 'on to', 'on tuesday', 'on wednesday', 'on your', 'once you', 'one of', 'one or', 'only the', 'opportunity to', 'or any', 'or if', 'or mail', 'or more', 'or not', 'or the', 'or to', 'or your', 'order for', 'order to', 'original message', 'other than', 'our group', 'our meeting', 'our site', 'our web', 'our website', 'out of', 'out that', 'out the', 'out to', 'over the', 'part of', 'participate in', 'participation in', 'patrick hou', 'paulo issler', 'people to', 'people who', 'phone 713', 'phone number', 'pinnamaneni krishnarao', 'plan to', 'planning to', 'please advise', 'please call', 'please click', 'please contact', 'please do', 'please feel', 'please find', 'please give', 'please let', 'please make', 'please note', 'please respond', 'please see', 'please send', 'please take', 'please visit', 'pleased to', 'pm from', 'pm please', 'pm subject', 'pm to', 'pm vince', 'po box', 'position in', 'possibility of', 'power and', 'presentation on', 'president of', 'price of', 'prices and', 'pricing and', 'prior to', 'process of', 'products and', 'program and', 'provide the', 'questions or', 'questions please', 'questions regarding', 'range of', 'rather than', 'ravi thuraisingham', 're enron', 'read the', 'ready to', 'real options', 'real time', 'receive this', 'received from', 'received this', 'receiving this', 'regarding the', 'related to', 'removed from', 'reply to', 'request for', 'requested for', 'research and', 'research enron', 'research group', 'respond to', 'response to', 'responsible for', 'rest of', 'result of', 'resume doc', 'resume to', 'return path', 'review and', 'review the', 'rice edu', 'rice university', 'right now', 'risk management', 'roberts hou', 'role in', 'said that', 'sandeep kohli', 'save your', 'scheduled for', 'school of', 'search engines', 'search for', 'see attached', 'see if', 'see the', 'see what', 'see you', 'seeing you', 'seems to', 'send it', 'send me', 'send the', 'send you', 'sending you', 'sent by', 'sent friday', 'sent monday', 'sent thursday', 'sent to', 'sent tuesday', 'sent wednesday', 'sent you', 'set up', 'shall be', 'shall send', 'shanbhogue hou', 'she is', 'shirley crenshaw', 'shirley please', 'short term', 'should be', 'should not', 'should you', 'since the', 'since we', 'site and', 'smith street', 'so far', 'so much', 'so please', 'so that', 'so we', 'so you', 'some of', 'some time', 'soon as', 'sorry for', 'spoke with', 'sponsored by', 'stanford edu', 'state of', 'steven leppard', 'stinson gibner', 'subject enron', 'subject fw', 'subject interview', 'subject new', 'subject re', 'subject request', 'subject the', 'subject to', 'subject your', 'success of', 'such as', 'summary of', 'summer internship', 'support for', 'sure that', 'take advantage', 'take look', 'take the', 'talk about', 'talk to', 'talked to', 'talking to', 'talking with', 'tanya tamarchenko', 'ted murphy', 'terms of', 'texas at', 'th and', 'th floor', 'th of', 'than the', 'thank you', 'thanks again', 'thanks and', 'thanks for', 'thanks kevin', 'thanks shirley', 'thanks vince', 'that all', 'that am', 'that are', 'that can', 'that could', 'that enron', 'that have', 'that he', 'that if', 'that is', 'that it', 'that may', 'that the', 'that there', 'that they', 'that this', 'that was', 'that we', 'that will', 'that would', 'that you', 'that your', 'the ability', 'the above', 'the attached', 'the best', 'the book', 'the business', 'the case', 'the company', 'the conference', 'the cost', 'the course', 'the credit', 'the current', 'the data', 'the date', 'the day', 'the details', 'the development', 'the email', 'the end', 'the energy', 'the enron', 'the entire', 'the fact', 'the final', 'the financial', 'the first', 'the following', 'the form', 'the full', 'the future', 'the global', 'the group', 'the industry', 'the information', 'the internet', 'the interview', 'the job', 'the key', 'the last', 'the latest', 'the link', 'the list', 'the long', 'the mail', 'the market', 'the meeting', 'the message', 'the model', 'the money', 'the morning', 'the most', 'the new', 'the next', 'the number', 'the office', 'the one', 'the only', 'the opportunity', 'the original', 'the other', 'the paper', 'the past', 'the person', 'the phone', 'the position', 'the possibility', 'the power', 'the presentation', 'the price', 'the problem', 'the process', 'the program', 'the project', 'the proposed', 'the real', 'the research', 'the rest', 'the results', 'the resume', 'the right', 'the risk', 'the same', 'the second', 'the sender', 'the software', 'the state', 'the students', 'the subject', 'the summer', 'the system', 'the th', 'the time', 'the trading', 'the two', 'the uk', 'the united', 'the university', 'the us', 'the use', 'the way', 'the weather', 'the web', 'the week', 'the wharton', 'the work', 'the world', 'the year', 'them to', 'there are', 'there is', 'there will', 'these are', 'they are', 'they can', 'they have', 'they will', 'they would', 'think about', 'think it', 'think that', 'think the', 'think we', 'think you', 'thinking of', 'third party', 'this area', 'this email', 'this information', 'this is', 'this issue', 'this list', 'this mail', 'this matter', 'this message', 'this morning', 'this opportunity', 'this point', 'this program', 'this project', 'this request', 'this time', 'this to', 'this week', 'this will', 'this would', 'this year', 'thousands of', 'through the', 'time and', 'time for', 'time the', 'time to', 'to access', 'to all', 'to an', 'to any', 'to arrange', 'to ask', 'to assist', 'to attend', 'to be', 'to bring', 'to buy', 'to call', 'to cc', 'to change', 'to check', 'to come', 'to complete', 'to confirm', 'to contact', 'to continue', 'to create', 'to date', 'to determine', 'to develop', 'to discuss', 'to do', 'to enron', 'to ensure', 'to find', 'to follow', 'to get', 'to give', 'to go', 'to have', 'to hear', 'to hearing', 'to help', 'to her', 'to him', 'to houston', 'to include', 'to inform', 'to interview', 'to invite', 'to john', 'to join', 'to keep', 'to know', 'to learn', 'to let', 'to look', 'to make', 'to me', 'to meet', 'to meeting', 'to move', 'to my', 'to obtain', 'to offer', 'to one', 'to our', 'to participate', 'to pay', 'to present', 'to provide', 'to put', 'to read', 'to receive', 'to review', 'to run', 'to save', 'to say', 'to schedule', 'to see', 'to seeing', 'to send', 'to set', 'to shirley', 'to some', 'to speak', 'to start', 'to stay', 'to stinson', 'to support', 'to take', 'to talk', 'to thank', 'to that', 'to the', 'to their', 'to this', 'to to', 'to understand', 'to unsubscribe', 'to us', 'to use', 'to vince', 'to visit', 'to vkamins', 'to wait', 'to work', 'to working', 'to you', 'to your', 'today and', 'together with', 'touch with', 'trading and', 'trip to', 'try to', 'trying to', 'two weeks', 'tx 76798', 'tx 77002', 'type of', 'unable to', 'under the', 'understand that', 'understand the', 'understanding of', 'united states', 'university of', 'university po', 'up and', 'up for', 'up on', 'up the', 'up to', 'up with', 'upenn edu', 'us at', 'us in', 'us know', 'us to', 'use of', 'use the', 'used in', 'used to', 'using the', 'utexas edu', 'value of', 'vasant shanbhogue', 've been', 'version of', 'very interested', 'very much', 'vice president', 'vince am', 'vince and', 'vince forwarded', 'vince from', 'vince have', 'vince here', 'vince just', 'vince kaminski', 'vince sent', 'vince thanks', 'vince this', 'vince will', 'vince would', 'vincent kaminski', 'visit our', 'visit to', 'vkamins enron', 'vkaminski aol', 'waco tx', 'want to', 'wanted to', 'wants to', 'was not', 'was the', 'way to', 'we also', 'we are', 'we can', 'we could', 'we discussed', 'we do', 'we don', 'we had', 'we have', 'we hope', 'we ll', 'we look', 'we may', 'we need', 'we offer', 'we provide', 'we re', 'we shall', 'we should', 'we ve', 'we want', 'we were', 'we will', 'we would', 'weather derivatives', 'web http', 'web site', 'web sites', 'website and', 'week of', 'welcome to', 'well as', 'wharton upenn', 'what do', 'what is', 'what the', 'what we', 'what you', 'when the', 'when we', 'when you', 'where the', 'where we', 'where you', 'which are', 'which is', 'which we', 'which will', 'which you', 'who are', 'who is', 'who will', 'will allow', 'will also', 'will be', 'will call', 'will contact', 'will continue', 'will find', 'will get', 'will give', 'will have', 'will make', 'will need', 'will not', 'will provide', 'will receive', 'will see', 'will send', 'will take', 'will try', 'will work', 'willing to', 'wish to', 'with all', 'with an', 'with any', 'with enron', 'with him', 'with it', 'with me', 'with my', 'with no', 'with our', 'with some', 'with the', 'with them', 'with this', 'with us', 'with vince', 'with you', 'with your', 'within the', 'wondering if', 'work for', 'work in', 'work on', 'work with', 'working on', 'working with', 'works for', 'would also', 'would appreciate', 'would be', 'would have', 'would like', 'would not', 'would work', 'would you', 'yahoo com', 'year and', 'you about', 'you again', 'you all', 'you an', 'you and', 'you are', 'you as', 'you at', 'you be', 'you best', 'you call', 'you can', 'you could', 'you do', 'you don', 'you feel', 'you for', 'you get', 'you guys', 'you had', 'you have', 'you if', 'you in', 'you know', 'you like', 'you ll', 'you may', 'you might', 'you must', 'you need', 'you on', 'you or', 'you please', 'you re', 'you regards', 'you should', 'you so', 'you soon', 'you that', 'you the', 'you think', 'you this', 'you to', 'you ve', 'you very', 'you vince', 'you want', 'you we', 'you were', 'you will', 'you wish', 'you with', 'you would', 'you wrote', 'your business', 'your company', 'your convenience', 'your email', 'your group', 'your help', 'your information', 'your mail', 'your message', 'your money', 'your name', 'your own', 'your participation', 'your presentation', 'your review', 'your schedule', 'your site', 'your thoughts', 'your time', 'your visit', 'your website', 'zimin lu']\n"
     ]
    }
   ],
   "source": [
    "# -------------------------- BIGRAM -------------\n",
    "\n",
    "print(\"BAG OF WORDS FOR BIGRAM\")\n",
    "print(unique_words2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
